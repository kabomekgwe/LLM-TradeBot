---
phase: 03-comprehensive-testing
plan: 02
type: execute
---

<objective>
Implement comprehensive tests for agent logic and risk management with 100% coverage.

Purpose: Validate all 8 agents return proper decisions, and ensure risk management prevents dangerous trades.
Output: Complete test coverage for agents (unit tests) and risk management (100% coverage safety-critical).
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-comprehensive-testing/DISCOVERY.md
@.planning/phases/03-comprehensive-testing/03-01-PLAN.md

**Codebase constraints:**
- Python 3.7+ with asyncio
- pytest-asyncio 1.3.0 with auto mode
- Agent pattern: `async def execute(context) -> dict`
- All agents return vote/confidence/reason dictionaries
- Risk management is safety-critical (100% coverage required)

**From codebase analysis (CONCERNS.md):**
- **Current issue**: 95%+ code untested, only test_providers.py exists with most tests skipped
- **Impact**: No validation that agents make correct decisions or that risk management prevents losses
- **Safety**: Risk management prevents over-leveraging and max loss violations (must have complete coverage)

**From DISCOVERY.md:**
- Agent testing: Mock indicators from QuantAnalyst, verify vote/confidence ranges
- Risk testing: 100% coverage required (safety-critical), test position sizing, max loss limits, leverage caps
- Parametrized fixtures reduce test duplication 30-60%
- AsyncMock for async agent execution

**Prior work:**
- Plan 03-01 completed - Test infrastructure and fixtures available (ohlcv_factory, mock_exchange, conftest.py)
- Phase 2 completed - All agents implemented with real TA-Lib indicators and ML predictions

**Why this matters:**
Agents make autonomous trading decisions worth real money. Without comprehensive tests, we can't verify they respond correctly to market conditions. Risk management is the only safeguard against catastrophic losses - 100% coverage ensures no code path can bypass safety limits.
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create comprehensive agent tests</name>
  <files>trading/tests/test_agents.py</files>
  <action>
Test all 8 agents with various market scenarios using fixtures from Plan 03-01.

**1. Create `trading/tests/test_agents.py`:**

```python
"""
Comprehensive tests for all 8 trading agents.
Tests decision-making logic across various market scenarios.
"""

import pytest
import pytest_asyncio
import numpy as np
from unittest.mock import AsyncMock, Mock

from trading.agents.quant_analyst import QuantAnalystAgent
from trading.agents.predict import PredictAgent
from trading.agents.bull import BullAgent
from trading.agents.bear import BearAgent
from trading.agents.risk_manager import RiskManagerAgent
from trading.agents.data_sync import DataSyncAgent
from trading.agents.executor import ExecutorAgent
from trading.agents.learning import LearningAgent
from trading.config import TradingConfig


# === QuantAnalystAgent Tests ===

@pytest.mark.asyncio
@pytest.mark.unit
async def test_quant_analyst_calculates_indicators(ohlcv_factory):
    """Test QuantAnalyst calculates RSI, MACD, Bollinger Bands."""
    # Arrange
    ohlcv_data = ohlcv_factory(trend="uptrend", num_candles=100)
    context = {'ohlcv_data': {'1h': ohlcv_data}}
    config = TradingConfig(symbol="BTC/USDT")
    agent = QuantAnalystAgent(config)

    # Act
    result = await agent.execute(context)

    # Assert
    indicators = result['indicators']
    assert 'rsi' in indicators
    assert 'macd' in indicators
    assert 'bollinger' in indicators

    # RSI should be between 0 and 100
    assert 0 <= indicators['rsi']['value'] <= 100

    # MACD should have macd, signal, histogram
    assert 'macd' in indicators['macd']
    assert 'signal' in indicators['macd']
    assert 'histogram' in indicators['macd']

    # Bollinger Bands should have upper, middle, lower
    assert 'upper' in indicators['bollinger']
    assert 'middle' in indicators['bollinger']
    assert 'lower' in indicators['bollinger']
    assert indicators['bollinger']['upper'] > indicators['bollinger']['middle']
    assert indicators['bollinger']['middle'] > indicators['bollinger']['lower']


@pytest.mark.asyncio
@pytest.mark.unit
async def test_quant_analyst_detects_overbought_oversold(ohlcv_factory):
    """Test QuantAnalyst detects overbought/oversold conditions."""
    # Create strong uptrend (should produce high RSI)
    ohlcv_data = ohlcv_factory(trend="uptrend", num_candles=100, volatility=0.01)
    context = {'ohlcv_data': {'1h': ohlcv_data}}
    config = TradingConfig(symbol="BTC/USDT")
    agent = QuantAnalystAgent(config)

    result = await agent.execute(context)
    rsi = result['indicators']['rsi']

    # Strong uptrend should produce high RSI (may not be overbought every time, but should be elevated)
    assert rsi['value'] > 40  # At least above neutral


# === PredictAgent Tests ===

@pytest.mark.asyncio
@pytest.mark.unit
@pytest.mark.ml
async def test_predict_agent_with_model(mock_lightgbm_model):
    """Test PredictAgent returns ML prediction with trained model."""
    # Arrange
    config = TradingConfig(symbol="BTC/USDT")
    agent = PredictAgent(config)
    agent.model = mock_lightgbm_model  # Inject mock model

    indicators = {
        'rsi': {'value': 65},
        'macd': {'macd': 0.5, 'signal': 0.3, 'histogram': 0.2},
        'bollinger': {'upper': 30100, 'middle': 30000, 'lower': 29900}
    }
    context = {'quant_analyst': {'indicators': indicators}}

    # Act
    result = await agent.execute(context)

    # Assert
    assert 'prediction' in result
    assert 'confidence' in result
    assert result['prediction'] in [1, -1]  # Bullish or bearish
    assert 0.0 <= result['confidence'] <= 1.0


@pytest.mark.asyncio
@pytest.mark.unit
async def test_predict_agent_without_model():
    """Test PredictAgent returns neutral fallback without trained model."""
    # Arrange
    config = TradingConfig(symbol="BTC/USDT")
    agent = PredictAgent(config)
    agent.model = None  # No model loaded

    context = {'quant_analyst': {'indicators': {}}}

    # Act
    result = await agent.execute(context)

    # Assert
    assert result['prediction'] == 0.0
    assert result['confidence'] == 0.0
    assert 'No trained model' in result['reason']


# === BullAgent Tests ===

@pytest.mark.asyncio
@pytest.mark.unit
@pytest.mark.parametrize("rsi_value,macd_bullish,bb_position,expected_vote", [
    (25, True, 'lower', 1.0),  # Strong bullish: oversold + bullish MACD + lower BB
    (45, True, 'middle_lower', 1.0),  # Moderate bullish
    (55, False, 'middle', 0.0),  # Neutral: no strong signals
    (75, False, 'upper', 0.0),  # Bearish conditions (bull agent abstains)
])
async def test_bull_agent_decision_logic(rsi_value, macd_bullish, bb_position, expected_vote):
    """Test BullAgent votes correctly based on technical indicators."""
    # Arrange
    config = TradingConfig(symbol="BTC/USDT")
    agent = BullAgent(config)

    indicators = {
        'rsi': {'value': rsi_value, 'oversold': rsi_value < 30, 'overbought': rsi_value > 70},
        'macd': {'bullish': macd_bullish, 'histogram': 0.2 if macd_bullish else -0.2},
        'bollinger': {'position': bb_position}
    }
    context = {'quant_analyst': {'indicators': indicators}}

    # Act
    result = await agent.execute(context)

    # Assert
    assert result['vote'] == expected_vote
    assert 0.0 <= result['confidence'] <= 1.0


# === BearAgent Tests ===

@pytest.mark.asyncio
@pytest.mark.unit
@pytest.mark.parametrize("rsi_value,macd_bullish,bb_position,expected_vote", [
    (75, False, 'upper', -1.0),  # Strong bearish: overbought + bearish MACD + upper BB
    (55, False, 'middle_upper', -1.0),  # Moderate bearish
    (45, True, 'middle', 0.0),  # Neutral: no strong signals
    (25, True, 'lower', 0.0),  # Bullish conditions (bear agent abstains)
])
async def test_bear_agent_decision_logic(rsi_value, macd_bullish, bb_position, expected_vote):
    """Test BearAgent votes correctly based on technical indicators."""
    # Arrange
    config = TradingConfig(symbol="BTC/USDT")
    agent = BearAgent(config)

    indicators = {
        'rsi': {'value': rsi_value, 'oversold': rsi_value < 30, 'overbought': rsi_value > 70},
        'macd': {'bullish': macd_bullish, 'histogram': 0.2 if macd_bullish else -0.2},
        'bollinger': {'position': bb_position}
    }
    context = {'quant_analyst': {'indicators': indicators}}

    # Act
    result = await agent.execute(context)

    # Assert
    assert result['vote'] == expected_vote
    assert 0.0 <= result['confidence'] <= 1.0


# === DataSyncAgent Tests ===

@pytest.mark.asyncio
@pytest.mark.integration
async def test_data_sync_fetches_ohlcv(mock_exchange):
    """Test DataSyncAgent fetches OHLCV data from exchange."""
    # Arrange
    config = TradingConfig(symbol="BTC/USDT")
    agent = DataSyncAgent(config)

    # Act
    result = await agent.execute({'exchange': mock_exchange})

    # Assert
    assert 'ohlcv_data' in result
    mock_exchange.fetch_ohlcv.assert_called()


# === ExecutorAgent Tests ===

@pytest.mark.asyncio
@pytest.mark.integration
async def test_executor_places_order(mock_exchange):
    """Test ExecutorAgent places order based on decision."""
    # Arrange
    config = TradingConfig(symbol="BTC/USDT")
    agent = ExecutorAgent(config)

    decision = {
        'action': 'buy',
        'quantity': 0.01,
        'confidence': 0.8
    }
    context = {'decision': decision, 'exchange': mock_exchange}

    # Act
    result = await agent.execute(context)

    # Assert
    assert 'order' in result
    mock_exchange.create_order.assert_called()


@pytest.mark.asyncio
@pytest.mark.integration
async def test_executor_skips_on_hold(mock_exchange):
    """Test ExecutorAgent skips execution when decision is hold."""
    # Arrange
    config = TradingConfig(symbol="BTC/USDT")
    agent = ExecutorAgent(config)

    decision = {'action': 'hold'}
    context = {'decision': decision, 'exchange': mock_exchange}

    # Act
    result = await agent.execute(context)

    # Assert
    mock_exchange.create_order.assert_not_called()


# === LearningAgent Tests ===

@pytest.mark.asyncio
@pytest.mark.unit
async def test_learning_agent_records_outcome():
    """Test LearningAgent records decision outcomes."""
    # Arrange
    config = TradingConfig(symbol="BTC/USDT")
    agent = LearningAgent(config)

    context = {
        'decision': {'action': 'buy', 'confidence': 0.8},
        'execution': {'filled': 0.01, 'price': 30000},
        'outcome': {'profit_loss': 150, 'pnl_percent': 5.0}
    }

    # Act
    result = await agent.execute(context)

    # Assert
    assert 'recorded' in result
    assert result['recorded'] == True
```

**What to avoid:**
- Don't skip edge cases (test with no indicators, missing fields, extreme values)
- Don't test implementation details (test behavior, not internal state)
- Don't create brittle tests (use ranges for confidence, not exact values)
- Don't ignore async patterns (always use @pytest.mark.asyncio)

**Why these choices:**
- Parametrized tests reduce duplication (same test logic, different inputs)
- Mock model injection tests agent logic independently of ML training
- Behavioral testing verifies agents respond correctly to market conditions
- Integration tests validate agent interactions with external systems (exchange)
  </action>
  <verify>
1. Tests run: `pytest trading/tests/test_agents.py -v` passes
2. Markers work: `pytest -m unit` runs only unit tests
3. Coverage measured: `pytest --cov=trading/agents` shows coverage percentages
4. All agents tested: Verify QuantAnalyst, Predict, Bull, Bear, DataSync, Executor, Learning have tests
  </verify>
  <done>
- Comprehensive test suite for all 8 agents
- Unit tests for decision logic with parametrized scenarios
- Integration tests for exchange interactions
- Mock fixtures used to isolate agent logic
- Behavioral testing verifies correct responses to market conditions
  </done>
</task>

<task type="auto">
  <name>Task 2: Create 100% coverage risk management tests</name>
  <files>trading/tests/test_risk.py</files>
  <action>
Test all risk management code paths with complete coverage (safety-critical requirement).

**1. Create `trading/tests/test_risk.py`:**

```python
"""
100% coverage tests for risk management (safety-critical module).
Tests position sizing, max loss limits, leverage caps, and all edge cases.
"""

import pytest
import pytest_asyncio
from unittest.mock import AsyncMock, Mock

from trading.agents.risk_manager import RiskManagerAgent
from trading.config import TradingConfig


# === Position Sizing Tests ===

@pytest.mark.asyncio
@pytest.mark.unit
@pytest.mark.risk
async def test_risk_manager_calculates_position_size():
    """Test RiskManager calculates position size based on risk parameters."""
    # Arrange
    config = TradingConfig(
        symbol="BTC/USDT",
        max_position_size=0.1,
        risk_per_trade=0.02  # 2% risk per trade
    )
    agent = RiskManagerAgent(config)

    context = {
        'balance': {'USDT': {'free': 10000}},
        'decision': {'action': 'buy', 'confidence': 0.8},
        'current_price': 30000
    }

    # Act
    result = await agent.execute(context)

    # Assert
    assert 'position_size' in result
    assert result['position_size'] > 0
    assert result['position_size'] <= config.max_position_size


@pytest.mark.asyncio
@pytest.mark.unit
@pytest.mark.risk
async def test_risk_manager_respects_max_position_size():
    """Test RiskManager never exceeds max position size limit."""
    # Arrange
    config = TradingConfig(
        symbol="BTC/USDT",
        max_position_size=0.05,  # 5% max position
        risk_per_trade=0.10  # 10% risk (should be capped by max_position_size)
    )
    agent = RiskManagerAgent(config)

    context = {
        'balance': {'USDT': {'free': 10000}},
        'decision': {'action': 'buy', 'confidence': 1.0},  # Max confidence
        'current_price': 30000
    }

    # Act
    result = await agent.execute(context)

    # Assert - Position size should be capped at max_position_size
    expected_max_position = 10000 * config.max_position_size / 30000
    assert result['position_size'] <= expected_max_position


# === Max Loss Protection Tests ===

@pytest.mark.asyncio
@pytest.mark.unit
@pytest.mark.risk
async def test_risk_manager_blocks_trade_when_max_loss_reached():
    """Test RiskManager vetoes trades when max loss limit is reached."""
    # Arrange
    config = TradingConfig(
        symbol="BTC/USDT",
        max_daily_loss=500  # $500 max daily loss
    )
    agent = RiskManagerAgent(config)

    context = {
        'balance': {'USDT': {'free': 10000}},
        'decision': {'action': 'buy', 'confidence': 0.8},
        'daily_pnl': -550,  # Already lost $550 today (exceeded limit)
        'current_price': 30000
    }

    # Act
    result = await agent.execute(context)

    # Assert - Trade should be vetoed
    assert result['action'] == 'hold'
    assert 'max loss reached' in result['reason'].lower()


@pytest.mark.asyncio
@pytest.mark.unit
@pytest.mark.risk
async def test_risk_manager_allows_trade_within_loss_limit():
    """Test RiskManager allows trades when within max loss limit."""
    # Arrange
    config = TradingConfig(
        symbol="BTC/USDT",
        max_daily_loss=500
    )
    agent = RiskManagerAgent(config)

    context = {
        'balance': {'USDT': {'free': 10000}},
        'decision': {'action': 'buy', 'confidence': 0.8},
        'daily_pnl': -200,  # Lost $200 today (within limit)
        'current_price': 30000
    }

    # Act
    result = await agent.execute(context)

    # Assert - Trade should be allowed
    assert result['action'] != 'hold'


# === Leverage Tests ===

@pytest.mark.asyncio
@pytest.mark.unit
@pytest.mark.risk
async def test_risk_manager_caps_leverage():
    """Test RiskManager enforces maximum leverage limit."""
    # Arrange
    config = TradingConfig(
        symbol="BTC/USDT",
        max_leverage=3.0  # 3x max leverage
    )
    agent = RiskManagerAgent(config)

    context = {
        'balance': {'USDT': {'free': 1000}},
        'decision': {'action': 'buy', 'confidence': 1.0},
        'requested_leverage': 5.0,  # Requesting 5x (should be capped)
        'current_price': 30000
    }

    # Act
    result = await agent.execute(context)

    # Assert
    assert result['leverage'] <= config.max_leverage


# === Insufficient Balance Tests ===

@pytest.mark.asyncio
@pytest.mark.unit
@pytest.mark.risk
async def test_risk_manager_blocks_trade_with_insufficient_balance():
    """Test RiskManager vetoes trades when insufficient balance."""
    # Arrange
    config = TradingConfig(symbol="BTC/USDT")
    agent = RiskManagerAgent(config)

    context = {
        'balance': {'USDT': {'free': 10}},  # Only $10 available
        'decision': {'action': 'buy', 'confidence': 0.8},
        'current_price': 30000,  # BTC at $30k (can't afford even 0.001 BTC)
        'min_order_size': 0.001
    }

    # Act
    result = await agent.execute(context)

    # Assert
    assert result['action'] == 'hold'
    assert 'insufficient balance' in result['reason'].lower()


# === Confidence-Based Position Sizing Tests ===

@pytest.mark.asyncio
@pytest.mark.unit
@pytest.mark.risk
@pytest.mark.parametrize("confidence,expected_scale", [
    (1.0, 1.0),  # Max confidence = full position
    (0.8, 0.8),  # 80% confidence = 80% position
    (0.5, 0.5),  # 50% confidence = 50% position
    (0.3, 0.3),  # Low confidence = small position
])
async def test_risk_manager_scales_position_by_confidence(confidence, expected_scale):
    """Test RiskManager scales position size based on decision confidence."""
    # Arrange
    config = TradingConfig(
        symbol="BTC/USDT",
        max_position_size=0.1,
        scale_by_confidence=True
    )
    agent = RiskManagerAgent(config)

    context = {
        'balance': {'USDT': {'free': 10000}},
        'decision': {'action': 'buy', 'confidence': confidence},
        'current_price': 30000
    }

    # Act
    result = await agent.execute(context)

    # Assert - Position size should scale with confidence
    max_position = 10000 * config.max_position_size / 30000
    expected_position = max_position * expected_scale

    # Allow 10% tolerance for rounding
    assert abs(result['position_size'] - expected_position) / expected_position < 0.1


# === Edge Cases ===

@pytest.mark.asyncio
@pytest.mark.unit
@pytest.mark.risk
async def test_risk_manager_handles_zero_balance():
    """Test RiskManager handles zero balance gracefully."""
    # Arrange
    config = TradingConfig(symbol="BTC/USDT")
    agent = RiskManagerAgent(config)

    context = {
        'balance': {'USDT': {'free': 0}},  # Zero balance
        'decision': {'action': 'buy', 'confidence': 0.8},
        'current_price': 30000
    }

    # Act
    result = await agent.execute(context)

    # Assert
    assert result['action'] == 'hold'
    assert result['position_size'] == 0


@pytest.mark.asyncio
@pytest.mark.unit
@pytest.mark.risk
async def test_risk_manager_handles_missing_balance():
    """Test RiskManager handles missing balance data gracefully."""
    # Arrange
    config = TradingConfig(symbol="BTC/USDT")
    agent = RiskManagerAgent(config)

    context = {
        'balance': {},  # Missing balance data
        'decision': {'action': 'buy', 'confidence': 0.8},
        'current_price': 30000
    }

    # Act
    result = await agent.execute(context)

    # Assert - Should fail safe (veto trade)
    assert result['action'] == 'hold'


@pytest.mark.asyncio
@pytest.mark.unit
@pytest.mark.risk
async def test_risk_manager_handles_hold_decision():
    """Test RiskManager passes through hold decisions without calculation."""
    # Arrange
    config = TradingConfig(symbol="BTC/USDT")
    agent = RiskManagerAgent(config)

    context = {
        'decision': {'action': 'hold'},  # Already decided to hold
    }

    # Act
    result = await agent.execute(context)

    # Assert
    assert result['action'] == 'hold'
    assert 'position_size' not in result  # No sizing needed for hold
```

**What to avoid:**
- Don't skip edge cases (zero balance, missing data, extreme values)
- Don't test internal calculations (test safety outcomes: "does it block dangerous trades?")
- Don't allow ANY uncovered code path (100% coverage required)
- Don't ignore fail-safe behavior (missing data should veto trades)

**Why these choices:**
- Parametrized confidence tests validate scaling logic across confidence range
- Edge case tests ensure fail-safe behavior (missing data → veto trade)
- 100% coverage ensures no code path can bypass safety limits
- Behavioral tests verify "does it prevent losses?" not "how does it calculate?"
- Safety-critical module requires complete test coverage (no gaps allowed)
  </action>
  <verify>
1. 100% coverage: `pytest --cov=trading/agents/risk_manager --cov-report=term-missing` shows 100%
2. All tests pass: `pytest trading/tests/test_risk.py -v` passes
3. Risk marker works: `pytest -m risk` runs only risk management tests
4. Edge cases covered: Verify zero balance, missing data, exceeded limits all tested
  </verify>
  <done>
- 100% test coverage for RiskManagerAgent (safety-critical requirement met)
- Position sizing tests validate size calculation and limits
- Max loss protection tests ensure trade vetoes when limits exceeded
- Leverage cap tests verify enforcement of maximum leverage
- Confidence scaling tests validate position size adjustment
- Edge case tests ensure fail-safe behavior (missing data → veto trade)
- Complete coverage of all risk management code paths
  </done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] Agent tests created for all 8 agents
- [ ] Parametrized tests reduce test duplication
- [ ] Risk management tests achieve 100% coverage
- [ ] All safety-critical code paths tested (position sizing, max loss, leverage)
- [ ] Edge cases handled (zero balance, missing data, extreme values)
- [ ] Behavioral testing validates correct decisions, not implementation details
- [ ] All tests pass with pytest -v
</verification>

<success_criteria>

- Both tasks completed successfully
- All 8 agents have comprehensive unit tests
- RiskManagerAgent has 100% test coverage (safety-critical)
- Parametrized fixtures reduce test duplication
- Edge cases and fail-safe behavior tested
- Ready for Plan 03-03 (ML & Integration Tests)
</success_criteria>

<output>
After completion, create `.planning/phases/03-comprehensive-testing/03-02-SUMMARY.md`:

# Phase 3 Plan 2: Agent & Risk Tests Summary

**[One-liner describing what shipped]**

## Accomplishments

- Created comprehensive test suite for all 8 agents
- Achieved 100% coverage for risk management (safety-critical)
- [Additional accomplishments]

## Files Created/Modified

- `trading/tests/test_agents.py` - Comprehensive agent decision logic tests
- `trading/tests/test_risk.py` - 100% coverage risk management tests

## Decisions Made

- Parametrized tests for Bull/Bear agents (reduce duplication)
- Behavioral testing over implementation testing
- Fail-safe requirement: missing data must veto trades
- [Other decisions]

## Deviations from Plan

[Document any deviations using deviation rules, or "None"]

## Issues Encountered

[Problems and resolutions, or "None"]

## Verification Results

[Results of verification checklist]

## Next Step

Ready for 03-03-PLAN.md (ML & Integration Tests)
</output>

# Phase 5: Enhanced Feature Engineering - Plan 05-01

**Plan:** 05-01-enhanced-feature-engineering
**Phase:** 5 of 8
**Created:** 2025-12-27
**Status:** Ready for execution

## Objective

Extend the existing feature engineering pipeline with four new feature categories: market microstructure (order book depth, bid-ask spread, trade imbalance), sentiment signals (crypto fear/greed index), time-based features (trading sessions, holidays, day-of-week), and volatility regime detection (HMM-based state classification). Migrate existing technical indicators from hand-rolled implementations to pandas-ta for battle-tested calculations that handle edge cases correctly.

This builds upon the existing `trading/ml/feature_engineering.py` (50+ features across 7 categories) by adding specialized financial signals that capture market microstructure, investor sentiment, temporal patterns, and volatility regimes - all critical for ML model accuracy.

## Context

**Project state:**
- @.planning/STATE.md - Phase 5 ready to plan (v1.0 complete, YOLO mode enabled)
- @.planning/ROADMAP.md - Phase 5: Enhanced Feature Engineering goals
- @.planning/phases/05-enhanced-feature-engineering/05-RESEARCH.md - Comprehensive ecosystem research (pandas-ta, CCXT, Alternative.me, pandas_market_calendars, HMM)

**Existing architecture:**
- `/Users/kabo/Desktop/LLM-TradeBot/trading/ml/feature_engineering.py` - Current FeatureEngineer class with 50+ hand-rolled features (returns, technical, volatility, momentum, volume, price patterns, statistical)
- Technical indicators already implemented: SMA, EMA, MACD, RSI, Bollinger Bands, ATR, ROC, Williams %R, OBV, VWAP
- Feature categories architecture: Dict-based feature_categories tracking

**Research findings:**
- pandas-ta preferred over TA-Lib (pure Python, easier installation, actively maintained)
- CCXT already in project - use for order book depth and bid-ask spread
- Alternative.me Fear & Greed Index - free crypto sentiment API (no API key required)
- pandas_market_calendars - 50+ exchange calendars for session detection
- Hidden Markov Models (statsmodels) - volatility regime detection (low/high states)
- **Critical**: Prevent look-ahead bias using `pd.merge_asof(direction='backward')`
- **Critical**: Prevent data leakage by fitting scaler ONLY on training data

**Decisions from v1.0:**
- Binary classification for ML (price direction up/down) - STATE.md line 156
- 5-candle lookahead for labels (balances prediction horizon) - STATE.md line 157
- Timeout values per operation type (OHLCV 30s, agents 60s) - STATE.md line 176
- Fail-fast validation at boundaries - STATE.md line 154

## Prerequisites

**Required dependencies:**
```bash
pip install pandas-ta fear-and-greed-crypto pandas_market_calendars statsmodels
```

**Existing code to review:**
- `/Users/kabo/Desktop/LLM-TradeBot/trading/ml/feature_engineering.py` - FeatureEngineer class to extend
- `/Users/kabo/Desktop/LLM-TradeBot/providers/` - CCXT exchange integration patterns

**Data requirements:**
- OHLCV data from CCXT (already integrated)
- Order book access via CCXT fetch_order_book()
- Internet access for Alternative.me API

## Tasks

**Scope:** 3 tasks, estimated ~45% context (fits single plan)

---

<task id="1" checkpoint="auto">
<name>Install dependencies and migrate to pandas-ta</name>

<objective>
Install pandas-ta, fear-and-greed-crypto, pandas_market_calendars, statsmodels. Migrate existing hand-rolled technical indicators (RSI, MACD, Bollinger Bands, ATR) from feature_engineering.py to pandas-ta implementations to prevent calculation edge cases (unstable periods, NaN handling, smoothing errors).
</objective>

<reason>
Research shows hand-rolled indicators miss edge cases (ATR unstable period, RSI first 14 candles, MACD smoothing). pandas-ta provides battle-tested implementations with 30+ years of established research. Migration prevents silent calculation bugs that corrupt ML training.
</reason>

<instructions>
1. **Install dependencies**
   ```bash
   cd /Users/kabo/Desktop/LLM-TradeBot
   pip install pandas-ta fear-and-greed-crypto pandas_market_calendars statsmodels hmmlearn
   ```
   - Add to requirements.txt: pandas-ta, fear-and-greed-crypto, pandas_market_calendars, statsmodels, hmmlearn
   - Verify installation: `python -c "import pandas_ta; import fear_and_greed; import pandas_market_calendars; import statsmodels"`

2. **Migrate RSI to pandas-ta** in `trading/ml/feature_engineering.py`
   - Replace manual RSI calculation (lines 159-166) with:
   ```python
   import pandas_ta as ta

   # In _add_technical_indicators()
   for window in [14]:
       col_name = f'rsi_{window}'
       df[col_name] = ta.rsi(df['close'], length=window)
       self.feature_categories['technical'].append(col_name)
   ```
   - Remove: delta, gain, loss, rs intermediate calculations
   - Benefit: pandas-ta handles unstable period (first 14 candles) correctly

3. **Migrate MACD to pandas-ta**
   - Replace manual MACD calculation (lines 151-156) with:
   ```python
   macd_result = ta.macd(df['close'], fast=12, slow=26, signal=9)
   df['macd'] = macd_result['MACD_12_26_9']
   df['macd_signal'] = macd_result['MACDs_12_26_9']
   df['macd_histogram'] = macd_result['MACDh_12_26_9']
   self.feature_categories['technical'].extend(['macd', 'macd_signal', 'macd_histogram'])
   ```
   - Remove: ema_12, ema_26 intermediate calculations
   - Benefit: pandas-ta uses proper EMA smoothing for MACD signal line

4. **Migrate Bollinger Bands to pandas-ta**
   - Replace manual BB calculation (lines 169-181) with:
   ```python
   for window in [20]:
       bbands = ta.bbands(df['close'], length=window, std=2)
       df[f'bb_upper_{window}'] = bbands[f'BBU_{window}_2.0']
       df[f'bb_lower_{window}'] = bbands[f'BBL_{window}_2.0']
       df[f'bb_mid_{window}'] = bbands[f'BBM_{window}_2.0']
       # Keep existing bb_width and bb_position calculations
       df[f'bb_width_{window}'] = (df[f'bb_upper_{window}'] - df[f'bb_lower_{window}']) / df[f'bb_mid_{window}']
       df[f'bb_position_{window}'] = (df['close'] - df[f'bb_lower_{window}']) / (df[f'bb_upper_{window}'] - df[f'bb_lower_{window}'])
   ```
   - Benefit: pandas-ta handles NaN in rolling std correctly

5. **Migrate ATR to pandas-ta**
   - Replace manual ATR calculation (lines 188-196) with:
   ```python
   for window in [14]:
       col_name = f'atr_{window}'
       df[col_name] = ta.atr(df['high'], df['low'], df['close'], length=window)
       df[f'atr_ratio_{window}'] = df[col_name] / df['close']
       self.feature_categories['volatility'].extend([col_name, f'atr_ratio_{window}'])
   ```
   - Remove: high_low, high_close, low_close, true_range intermediate calculations
   - Benefit: pandas-ta handles ATR warm-up period (first 14 candles) correctly

6. **Verify migration**
   - Run existing tests: `pytest trading/tests/test_ml.py -k feature`
   - Ensure feature counts match (50+ features still generated)
   - Check no new NaN rows introduced (df.isna().sum() should be same or lower)
   - Verify feature_categories dict still tracks all features correctly

**Success criteria:**
- [ ] All 4 dependencies installed and added to requirements.txt
- [ ] RSI, MACD, Bollinger Bands, ATR migrated to pandas-ta
- [ ] Existing tests pass (same feature count, no new NaNs)
- [ ] feature_categories dict correctly updated
- [ ] No calculation errors in pandas-ta indicators

**Rollback plan:**
- Git revert to pre-migration state if tests fail
- Keep original calculations in comments until migration verified

**Validation:**
```python
# Quick validation
from trading.ml.feature_engineering import FeatureEngineer
import pandas as pd

# Create sample OHLCV
df = pd.DataFrame({
    'open': [100] * 100,
    'high': [105] * 100,
    'low': [95] * 100,
    'close': [102] * 100,
    'volume': [1000] * 100
})

engineer = FeatureEngineer()
features = engineer.transform(df)

# Should have 50+ features, no NaNs
assert len(features.columns) > 50
assert features.isna().sum().sum() == 0
print(f"✓ Generated {len(features.columns)} features from {len(features)} samples")
```
</instructions>
</task>

---

<task id="2" checkpoint="auto">
<name>Create market microstructure and sentiment feature modules</name>

<objective>
Create two new feature modules: `trading/features/microstructure.py` (CCXT order book depth, bid-ask spread, trade imbalance, mid-price) and `trading/features/sentiment.py` (Alternative.me Fear & Greed Index with historical data caching). Integrate into FeatureEngineer pipeline with strict timestamp alignment to prevent look-ahead bias.
</objective>

<reason>
Market microstructure captures order flow dynamics and liquidity conditions that impact execution and slippage. Sentiment signals (fear/greed) measure investor psychology and herd behavior. Both are proven ML features in quantitative finance research. Order book imbalance predicts short-term price movement, sentiment captures regime shifts.
</reason>

<instructions>
1. **Create trading/features/ directory**
   ```bash
   mkdir -p /Users/kabo/Desktop/LLM-TradeBot/trading/features
   touch /Users/kabo/Desktop/LLM-TradeBot/trading/features/__init__.py
   ```

2. **Create trading/features/microstructure.py**
   ```python
   """Market microstructure features from CCXT order book data.

   Extracts order book depth, bid-ask spread, trade imbalance, and mid-price
   from exchange L2 order book data via CCXT.
   """

   import logging
   import pandas as pd
   from typing import Dict, Any
   from trading.exceptions import APIError
   from trading.utils.timeout import with_timeout

   logger = logging.getLogger(__name__)

   class MicrostructureFeatures:
       """Extract market microstructure features from CCXT order book."""

       def __init__(self, depth_levels: int = 10):
           """Initialize microstructure feature extractor.

           Args:
               depth_levels: Number of order book levels to analyze (default 10)
           """
           self.depth_levels = depth_levels

       @with_timeout(10.0)  # 10s timeout for order book fetch
       async def extract_features(self, exchange, symbol: str) -> Dict[str, float]:
           """Extract microstructure features from current order book.

           Args:
               exchange: CCXT exchange instance
               symbol: Trading pair (e.g., 'BTC/USDT')

           Returns:
               Dictionary with keys: bid_ask_spread, spread_pct, mid_price,
                                    order_book_imbalance, bid_volume, ask_volume

           Raises:
               APIError: If order book fetch fails
           """
           try:
               # Fetch order book with depth
               order_book = await exchange.fetch_order_book(symbol, limit=self.depth_levels * 2)

               if not order_book['bids'] or not order_book['asks']:
                   raise APIError(f"Empty order book for {symbol}")

               # Best bid/ask prices
               best_bid = order_book['bids'][0][0]
               best_ask = order_book['asks'][0][0]

               # Bid-ask spread
               spread = best_ask - best_bid
               spread_pct = (spread / best_ask) * 100

               # Mid-price
               mid_price = (best_bid + best_ask) / 2

               # Order book imbalance (top N levels)
               bid_volume = sum([level[1] for level in order_book['bids'][:self.depth_levels]])
               ask_volume = sum([level[1] for level in order_book['asks'][:self.depth_levels]])

               # Normalized imbalance: -1 (all asks) to +1 (all bids)
               imbalance = (bid_volume - ask_volume) / (bid_volume + ask_volume) if (bid_volume + ask_volume) > 0 else 0.0

               logger.debug(f"Microstructure features for {symbol}: spread={spread_pct:.4f}%, imbalance={imbalance:.4f}")

               return {
                   'bid_ask_spread': spread,
                   'spread_pct': spread_pct,
                   'mid_price': mid_price,
                   'order_book_imbalance': imbalance,
                   'bid_volume': bid_volume,
                   'ask_volume': ask_volume,
               }

           except Exception as e:
               logger.error(f"Failed to extract microstructure features for {symbol}: {e}")
               raise APIError(f"Order book fetch failed: {e}") from e
   ```

3. **Create trading/features/sentiment.py**
   ```python
   """Sentiment features from Alternative.me Fear & Greed Index.

   Fetches crypto market sentiment (0-100 scale) from Alternative.me API.
   Caches historical data to prevent excessive API calls.
   """

   import logging
   import pandas as pd
   from datetime import datetime, timedelta
   from typing import Optional, Dict, Any
   from fear_and_greed import get_latest, get_historical
   from trading.exceptions import APIError

   logger = logging.getLogger(__name__)

   class SentimentFeatures:
       """Extract sentiment features from Fear & Greed Index."""

       def __init__(self):
           """Initialize sentiment feature extractor."""
           self._cache: Optional[pd.DataFrame] = None
           self._cache_updated: Optional[datetime] = None

       def get_current_sentiment(self) -> Dict[str, Any]:
           """Get current fear & greed index value.

           Returns:
               Dictionary with keys: value (0-100), classification (str), timestamp

           Raises:
               APIError: If API request fails
           """
           try:
               latest = get_latest()

               return {
                   'fear_greed_value': float(latest['value']),
                   'fear_greed_class': latest['value_classification'],
                   'timestamp': datetime.fromtimestamp(int(latest['timestamp']))
               }

           except Exception as e:
               logger.error(f"Failed to fetch current sentiment: {e}")
               raise APIError(f"Fear & Greed API failed: {e}") from e

       def get_historical_sentiment(self, days: int = 30, force_refresh: bool = False) -> pd.DataFrame:
           """Get historical fear & greed index data with caching.

           Args:
               days: Number of days of historical data (max 365)
               force_refresh: Force refresh cache even if recent

           Returns:
               DataFrame with columns: timestamp, value, value_classification

           Raises:
               APIError: If API request fails
           """
           # Check cache freshness (refresh daily)
           if not force_refresh and self._cache is not None and self._cache_updated is not None:
               if datetime.now() - self._cache_updated < timedelta(days=1):
                   logger.debug("Using cached sentiment data")
                   return self._cache.copy()

           try:
               # Fetch historical data
               historical = get_historical(limit=days)

               # Convert to DataFrame
               df = pd.DataFrame(historical)
               df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s')
               df = df.sort_values('timestamp')

               # Cache results
               self._cache = df
               self._cache_updated = datetime.now()

               logger.info(f"Fetched {len(df)} days of sentiment data")

               return df.copy()

           except Exception as e:
               logger.error(f"Failed to fetch historical sentiment: {e}")
               raise APIError(f"Fear & Greed historical API failed: {e}") from e

       def align_sentiment_to_ohlcv(self, ohlcv_df: pd.DataFrame, sentiment_df: pd.DataFrame) -> pd.DataFrame:
           """Align sentiment data to OHLCV timestamps preventing look-ahead bias.

           Args:
               ohlcv_df: DataFrame with OHLCV data (must have 'timestamp' column)
               sentiment_df: DataFrame with sentiment data (timestamp, value columns)

           Returns:
               OHLCV DataFrame with sentiment features added

           Raises:
               ValueError: If required columns missing
           """
           if 'timestamp' not in ohlcv_df.columns:
               raise ValueError("OHLCV DataFrame must have 'timestamp' column")

           if 'timestamp' not in sentiment_df.columns or 'value' not in sentiment_df.columns:
               raise ValueError("Sentiment DataFrame must have 'timestamp' and 'value' columns")

           # Use merge_asof with direction='backward' to prevent look-ahead bias
           # This ensures we only use sentiment data from past or present
           result = pd.merge_asof(
               ohlcv_df.sort_values('timestamp'),
               sentiment_df[['timestamp', 'value']].sort_values('timestamp').rename(columns={'value': 'fear_greed_index'}),
               on='timestamp',
               direction='backward'  # CRITICAL: Only use past sentiment
           )

           logger.debug(f"Aligned sentiment to {len(result)} OHLCV candles")

           return result
   ```

4. **Integrate into FeatureEngineer** (trading/ml/feature_engineering.py)
   - Add imports:
   ```python
   from trading.features.microstructure import MicrostructureFeatures
   from trading.features.sentiment import SentimentFeatures
   ```

   - Add to __init__:
   ```python
   self.microstructure = MicrostructureFeatures(depth_levels=10)
   self.sentiment = SentimentFeatures()
   self.feature_categories['microstructure'] = []
   self.feature_categories['sentiment'] = []
   ```

   - Add new method to call during transform():
   ```python
   def _add_microstructure_features(self, df: pd.DataFrame, exchange, symbol: str) -> pd.DataFrame:
       """Add market microstructure features (call once per prediction window)."""
       # Note: This would be called once per prediction, not per historical candle
       # For historical data, would need to fetch historical order book (not available in CCXT)
       # For now, document this as "live trading only" feature
       pass  # Implemented during live integration

   def _add_sentiment_features(self, df: pd.DataFrame) -> pd.DataFrame:
       """Add sentiment features with strict timestamp alignment."""
       try:
           # Ensure timestamp column exists
           if 'timestamp' not in df.columns:
               logger.warning("No timestamp column - cannot add sentiment features")
               return df

           # Fetch historical sentiment (cached daily)
           sentiment_df = self.sentiment.get_historical_sentiment(days=30)

           # Align to OHLCV timestamps (prevents look-ahead bias)
           df = self.sentiment.align_sentiment_to_ohlcv(df, sentiment_df)

           self.feature_categories['sentiment'].append('fear_greed_index')

           logger.info("Added sentiment features")

       except Exception as e:
           logger.warning(f"Could not add sentiment features: {e}")

       return df
   ```

   - Update transform() to call sentiment features:
   ```python
   # In transform() method, after existing features:
   data = self._add_sentiment_features(data)
   ```

5. **Verify integration**
   - Test sentiment feature alignment:
   ```python
   from trading.features.sentiment import SentimentFeatures
   import pandas as pd

   sentiment = SentimentFeatures()

   # Get current sentiment
   current = sentiment.get_current_sentiment()
   assert 0 <= current['fear_greed_value'] <= 100

   # Get historical
   historical = sentiment.get_historical_sentiment(days=7)
   assert len(historical) > 0
   assert 'timestamp' in historical.columns
   ```

**Success criteria:**
- [ ] trading/features/ directory created with __init__.py
- [ ] MicrostructureFeatures class implemented with timeout protection
- [ ] SentimentFeatures class implemented with daily caching
- [ ] merge_asof(direction='backward') used for timestamp alignment
- [ ] Sentiment features integrated into FeatureEngineer.transform()
- [ ] feature_categories tracks microstructure and sentiment features
- [ ] Tests verify sentiment alignment prevents look-ahead bias

**Rollback plan:**
- Remove trading/features/ directory
- Remove sentiment imports from feature_engineering.py
- System continues with existing 50+ features

**Validation:**
```python
# Verify sentiment alignment
from trading.ml.feature_engineering import FeatureEngineer
import pandas as pd
import numpy as np

# Create sample OHLCV with timestamps
df = pd.DataFrame({
    'timestamp': pd.date_range('2024-01-01', periods=100, freq='5min'),
    'open': np.random.random(100) * 100 + 100,
    'high': np.random.random(100) * 100 + 105,
    'low': np.random.random(100) * 100 + 95,
    'close': np.random.random(100) * 100 + 102,
    'volume': np.random.random(100) * 1000 + 500
})

engineer = FeatureEngineer()
features = engineer.transform(df)

# Should have fear_greed_index column
assert 'fear_greed_index' in features.columns
assert features['fear_greed_index'].notna().sum() > 0
print(f"✓ Sentiment features added: {features['fear_greed_index'].describe()}")
```
</instructions>
</task>

---

<task id="3" checkpoint="auto">
<name>Create time-based and volatility regime feature modules</name>

<objective>
Create two final feature modules: `trading/features/temporal.py` (trading sessions via pandas_market_calendars, day-of-week, hour-of-day, weekend detection, holiday flags) and `trading/features/regime.py` (Hidden Markov Model volatility regime detection for low/high volatility states). Integrate into FeatureEngineer pipeline.
</objective>

<reason>
Time-based features capture session effects (Asian/London/NY overlap), day-of-week patterns, and holiday impacts on liquidity. Volatility regime detection identifies market conditions (low/high volatility) enabling strategy adaptation. Both are established features in quantitative finance research - session effects drive intraday volume patterns, volatility regimes require different risk parameters.
</reason>

<instructions>
1. **Create trading/features/temporal.py**
   ```python
   """Time-based features using pandas_market_calendars.

   Extracts trading session, day-of-week, hour-of-day, weekend flags,
   and holiday detection from timestamp data.
   """

   import logging
   import pandas as pd
   import pandas_market_calendars as mcal
   from typing import Optional

   logger = logging.getLogger(__name__)

   class TemporalFeatures:
       """Extract time-based features from timestamps."""

       def __init__(self, calendar_name: str = 'NYSE'):
           """Initialize temporal feature extractor.

           Args:
               calendar_name: Market calendar to use (default: NYSE)
                             Options: NYSE, NASDAQ, LSE, TSX, BMF, HKEX, etc.
           """
           try:
               self.calendar = mcal.get_calendar(calendar_name)
               self.calendar_name = calendar_name
               logger.info(f"Initialized {calendar_name} market calendar")
           except Exception as e:
               logger.warning(f"Could not load {calendar_name} calendar: {e}. Using fallback.")
               self.calendar = None

       @staticmethod
       def get_trading_session(hour_utc: int) -> str:
           """Map UTC hour to major trading session.

           Args:
               hour_utc: Hour in UTC (0-23)

           Returns:
               Session name: 'Asia', 'London', 'New_York', or 'Off_Hours'
           """
           if 0 <= hour_utc < 8:
               return 'Asia'  # Tokyo open 0:00-8:00 UTC
           elif 8 <= hour_utc < 12:
               return 'London'  # London open 8:00-16:00 UTC (pre-NY)
           elif 12 <= hour_utc < 21:
               return 'New_York'  # NY overlap + exclusive 12:00-21:00 UTC
           else:
               return 'Off_Hours'  # 21:00-24:00 UTC

       def extract_features(self, df: pd.DataFrame) -> pd.DataFrame:
           """Add time-based features to DataFrame.

           Args:
               df: DataFrame with 'timestamp' column (datetime type)

           Returns:
               DataFrame with added temporal features

           Raises:
               ValueError: If 'timestamp' column missing or not datetime
           """
           if 'timestamp' not in df.columns:
               raise ValueError("DataFrame must have 'timestamp' column")

           if not pd.api.types.is_datetime64_any_dtype(df['timestamp']):
               logger.warning("Converting 'timestamp' to datetime")
               df['timestamp'] = pd.to_datetime(df['timestamp'])

           # Extract basic time components
           df['hour'] = df['timestamp'].dt.hour
           df['day_of_week'] = df['timestamp'].dt.dayofweek  # Monday=0, Sunday=6
           df['day_of_month'] = df['timestamp'].dt.day
           df['month'] = df['timestamp'].dt.month
           df['quarter'] = df['timestamp'].dt.quarter

           # Weekend flag
           df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)

           # Trading session
           df['session'] = df['hour'].apply(self.get_trading_session)

           # One-hot encode sessions
           df['session_asia'] = (df['session'] == 'Asia').astype(int)
           df['session_london'] = (df['session'] == 'London').astype(int)
           df['session_newyork'] = (df['session'] == 'New_York').astype(int)
           df['session_offhours'] = (df['session'] == 'Off_Hours').astype(int)

           # Holiday detection (if calendar available)
           if self.calendar is not None:
               try:
                   # Get trading schedule for date range
                   start_date = df['timestamp'].min().date()
                   end_date = df['timestamp'].max().date()
                   schedule = self.calendar.schedule(start_date=start_date, end_date=end_date)

                   # Mark holidays (dates NOT in schedule)
                   df['is_holiday'] = (~df['timestamp'].dt.date.isin(schedule.index.date)).astype(int)

                   logger.debug(f"Detected {df['is_holiday'].sum()} holiday candles")
               except Exception as e:
                   logger.warning(f"Could not detect holidays: {e}")
                   df['is_holiday'] = 0
           else:
               df['is_holiday'] = 0

           logger.info(f"Added temporal features to {len(df)} candles")

           return df
   ```

2. **Create trading/features/regime.py**
   ```python
   """Volatility regime detection using Hidden Markov Models.

   Classifies market into low/high volatility regimes using HMM
   with switching variance on returns.
   """

   import logging
   import numpy as np
   import pandas as pd
   from typing import Optional
   from statsmodels.tsa.regime_switching.markov_regression import MarkovRegression

   logger = logging.getLogger(__name__)

   class VolatilityRegimeDetector:
       """Detect volatility regimes using Hidden Markov Models."""

       def __init__(self, n_regimes: int = 2, min_periods: int = 100):
           """Initialize regime detector.

           Args:
               n_regimes: Number of volatility regimes (default: 2 for low/high)
               min_periods: Minimum data points required for HMM (default: 100)
           """
           self.n_regimes = n_regimes
           self.min_periods = min_periods
           self.model = None
           self.results = None

       def fit(self, returns: pd.Series) -> None:
           """Fit HMM to returns data.

           Args:
               returns: Series of returns (close.pct_change())

           Raises:
               ValueError: If insufficient data
           """
           # Remove NaN and check length
           returns_clean = returns.dropna()

           if len(returns_clean) < self.min_periods:
               raise ValueError(f"Insufficient data: need {self.min_periods}, got {len(returns_clean)}")

           try:
               # Fit Markov Regime Switching model
               self.model = MarkovRegression(
                   returns_clean,
                   k_regimes=self.n_regimes,
                   switching_variance=True,  # Key: variance switches between regimes
               )

               # Fit with error handling (HMM can fail to converge)
               self.results = self.model.fit(maxiter=100, disp=False)

               logger.info(f"HMM fitted with {self.n_regimes} regimes on {len(returns_clean)} returns")

           except Exception as e:
               logger.error(f"HMM fitting failed: {e}")
               raise

       def detect_regimes(self, df: pd.DataFrame, return_col: str = 'close') -> pd.DataFrame:
           """Detect volatility regimes in DataFrame.

           Args:
               df: DataFrame with OHLCV data
               return_col: Column to calculate returns from (default: 'close')

           Returns:
               DataFrame with regime probability and current regime columns

           Raises:
               ValueError: If return_col not in DataFrame or insufficient data
           """
           if return_col not in df.columns:
               raise ValueError(f"Column '{return_col}' not found in DataFrame")

           # Calculate returns
           returns = df[return_col].pct_change().dropna()

           # Fit HMM
           self.fit(returns)

           # Get smoothed regime probabilities
           # Index 0 = low volatility, Index 1 = high volatility (typically)
           regime_probs = self.results.smoothed_marginal_probabilities

           # Add regime features to dataframe (align with original df length)
           # Note: First row will be NaN due to pct_change()
           df['regime_prob_0'] = np.nan
           df['regime_prob_1'] = np.nan
           df['current_regime'] = np.nan

           # Fill from index 1 onwards (after first NaN from pct_change)
           df.loc[df.index[1:], 'regime_prob_0'] = regime_probs[0].values
           df.loc[df.index[1:], 'regime_prob_1'] = regime_probs[1].values
           df.loc[df.index[1:], 'current_regime'] = regime_probs.idxmax(axis=1).values

           # Identify which regime is low vs high volatility
           regime_0_var = self.results.params[f'sigma2.0']
           regime_1_var = self.results.params[f'sigma2.1']

           low_vol_regime = 0 if regime_0_var < regime_1_var else 1
           df['is_low_volatility'] = (df['current_regime'] == low_vol_regime).astype(int)

           logger.info(f"Detected regimes: Regime 0 var={regime_0_var:.6f}, Regime 1 var={regime_1_var:.6f}")
           logger.info(f"Low volatility regime: {low_vol_regime}")

           return df
   ```

3. **Integrate into FeatureEngineer** (trading/ml/feature_engineering.py)
   - Add imports:
   ```python
   from trading.features.temporal import TemporalFeatures
   from trading.features.regime import VolatilityRegimeDetector
   ```

   - Add to __init__:
   ```python
   self.temporal = TemporalFeatures(calendar_name='NYSE')
   self.regime_detector = VolatilityRegimeDetector(n_regimes=2, min_periods=100)
   self.feature_categories['temporal'] = []
   self.feature_categories['regime'] = []
   ```

   - Add new methods:
   ```python
   def _add_temporal_features(self, df: pd.DataFrame) -> pd.DataFrame:
       """Add time-based features."""
       try:
           df = self.temporal.extract_features(df)

           # Track temporal features
           self.feature_categories['temporal'].extend([
               'hour', 'day_of_week', 'day_of_month', 'month', 'quarter',
               'is_weekend', 'session_asia', 'session_london',
               'session_newyork', 'session_offhours', 'is_holiday'
           ])

           logger.info("Added temporal features")

       except Exception as e:
           logger.warning(f"Could not add temporal features: {e}")

       return df

   def _add_regime_features(self, df: pd.DataFrame) -> pd.DataFrame:
       """Add volatility regime features."""
       try:
           # Need sufficient data for HMM
           if len(df) < 100:
               logger.warning(f"Insufficient data for regime detection: {len(df)} < 100")
               return df

           df = self.regime_detector.detect_regimes(df, return_col='close')

           # Track regime features
           self.feature_categories['regime'].extend([
               'regime_prob_0', 'regime_prob_1', 'current_regime', 'is_low_volatility'
           ])

           logger.info("Added volatility regime features")

       except Exception as e:
           logger.warning(f"Could not add regime features: {e}")

       return df
   ```

   - Update transform() to call temporal and regime features:
   ```python
   # In transform() method, after sentiment features:
   data = self._add_temporal_features(data)
   data = self._add_regime_features(data)
   ```

4. **Update feature count documentation** (feature_engineering.py docstring)
   - Update class docstring:
   ```python
   """Feature Engineering - Generate ML features from OHLCV data.

   Implements 65+ features across multiple categories:
   - Returns (simple, log, forward)
   - Technical indicators (MA, RSI, MACD, Bollinger Bands) - pandas-ta
   - Volatility metrics (ATR, standard deviation, Keltner channels)
   - Momentum indicators (ROC, momentum, Williams %R)
   - Volume metrics (OBV, volume ratios, VWAP)
   - Price patterns (highs/lows, price position)
   - Statistical features (skewness, kurtosis, autocorrelation)
   - Sentiment (Fear & Greed Index from Alternative.me)
   - Temporal (sessions, day-of-week, holidays via pandas_market_calendars)
   - Regime (HMM-based volatility regime detection)
   """
   ```

5. **Verify integration**
   - Test temporal features:
   ```python
   from trading.features.temporal import TemporalFeatures
   import pandas as pd

   temporal = TemporalFeatures()

   df = pd.DataFrame({
       'timestamp': pd.date_range('2024-01-01', periods=100, freq='1h')
   })

   df = temporal.extract_features(df)

   assert 'session' in df.columns
   assert 'is_weekend' in df.columns
   assert df['session'].isin(['Asia', 'London', 'New_York', 'Off_Hours']).all()
   ```

   - Test regime detection:
   ```python
   from trading.features.regime import VolatilityRegimeDetector
   import pandas as pd
   import numpy as np

   detector = VolatilityRegimeDetector(n_regimes=2, min_periods=100)

   df = pd.DataFrame({
       'close': np.random.randn(200).cumsum() + 100  # Random walk
   })

   df = detector.detect_regimes(df, return_col='close')

   assert 'regime_prob_0' in df.columns
   assert 'current_regime' in df.columns
   assert 'is_low_volatility' in df.columns
   assert df['current_regime'].isin([0, 1]).any()
   ```

**Success criteria:**
- [ ] TemporalFeatures class created with pandas_market_calendars integration
- [ ] Session detection working (Asia/London/NY/Off_Hours)
- [ ] Holiday detection working via market calendar
- [ ] VolatilityRegimeDetector class created with HMM
- [ ] Regime detection identifies low/high volatility states
- [ ] Both feature modules integrated into FeatureEngineer
- [ ] feature_categories tracks temporal and regime features
- [ ] Documentation updated to reflect 65+ features

**Rollback plan:**
- Remove trading/features/temporal.py and regime.py
- Remove imports from feature_engineering.py
- System continues with existing 50+ features + sentiment

**Validation:**
```python
# End-to-end feature engineering validation
from trading.ml.feature_engineering import FeatureEngineer
import pandas as pd
import numpy as np

# Create sample OHLCV with timestamps (200 candles for HMM)
df = pd.DataFrame({
    'timestamp': pd.date_range('2024-01-01', periods=200, freq='5min'),
    'open': np.random.random(200) * 100 + 100,
    'high': np.random.random(200) * 100 + 105,
    'low': np.random.random(200) * 100 + 95,
    'close': np.random.random(200) * 100 + 102,
    'volume': np.random.random(200) * 1000 + 500
})

engineer = FeatureEngineer()
features = engineer.transform(df)

# Verify feature count (should be 65+)
assert len(features.columns) >= 65, f"Expected 65+ features, got {len(features.columns)}"

# Verify key feature categories present
assert 'fear_greed_index' in features.columns  # Sentiment
assert 'session_asia' in features.columns      # Temporal
assert 'is_low_volatility' in features.columns # Regime

print(f"✓ Generated {len(features.columns)} features from {len(features)} samples")
print(f"✓ Feature categories: {list(engineer.feature_categories.keys())}")
print(f"✓ Temporal features: {engineer.feature_categories['temporal']}")
print(f"✓ Regime features: {engineer.feature_categories['regime']}")
```
</instructions>
</task>

---

## Success Criteria

**Phase 5 complete when:**
- [ ] All 4 dependencies installed (pandas-ta, fear-and-greed-crypto, pandas_market_calendars, statsmodels)
- [ ] Existing technical indicators migrated to pandas-ta (RSI, MACD, BB, ATR)
- [ ] 4 new feature modules created (microstructure, sentiment, temporal, regime)
- [ ] Sentiment features integrated with look-ahead bias prevention (merge_asof)
- [ ] Temporal features detect trading sessions, holidays, day-of-week
- [ ] Volatility regime detection identifies low/high volatility states via HMM
- [ ] FeatureEngineer generates 65+ features (up from 50+)
- [ ] All existing tests pass (no regressions)
- [ ] Documentation updated with new feature categories

**Quality gates:**
- No calculation errors in pandas-ta indicators
- Sentiment alignment verified (no look-ahead bias)
- HMM converges on 100+ candle datasets
- feature_categories dict correctly tracks all 65+ features
- No new NaN rows introduced (dropna handles unstable periods)

## Verification

**After execution:**

```bash
# 1. Verify dependencies installed
python -c "import pandas_ta; import fear_and_greed; import pandas_market_calendars; import statsmodels; print('✓ All dependencies installed')"

# 2. Run ML tests
pytest trading/tests/test_ml.py -v

# 3. Test feature engineering pipeline
python -c "
from trading.ml.feature_engineering import FeatureEngineer
import pandas as pd
import numpy as np

df = pd.DataFrame({
    'timestamp': pd.date_range('2024-01-01', periods=200, freq='5min'),
    'open': np.random.random(200) * 100 + 100,
    'high': np.random.random(200) * 100 + 105,
    'low': np.random.random(200) * 100 + 95,
    'close': np.random.random(200) * 100 + 102,
    'volume': np.random.random(200) * 1000 + 500
})

engineer = FeatureEngineer()
features = engineer.transform(df)

print(f'✓ Generated {len(features.columns)} features')
print(f'✓ Feature categories: {list(engineer.feature_categories.keys())}')
assert len(features.columns) >= 65
"

# 4. Verify no regressions
git diff trading/ml/feature_engineering.py  # Should show pandas-ta migration
git status  # Should show new trading/features/ directory
```

**Expected output:**
```
✓ All dependencies installed
✓ Generated 67 features from 150 samples
✓ Feature categories: ['returns', 'technical', 'volatility', 'momentum', 'volume', 'price_patterns', 'statistical', 'sentiment', 'temporal', 'regime']
```

## Rollback Plan

If execution fails:

1. **Revert dependency installation:**
   ```bash
   pip uninstall pandas-ta fear-and-greed-crypto pandas_market_calendars statsmodels hmmlearn
   git checkout requirements.txt
   ```

2. **Revert code changes:**
   ```bash
   git checkout trading/ml/feature_engineering.py
   rm -rf trading/features/
   ```

3. **Verify system state:**
   ```bash
   pytest trading/tests/test_ml.py  # Should pass with original 50+ features
   ```

**System continues with:**
- Existing 50+ hand-rolled features (no regression)
- Original RSI, MACD, BB, ATR calculations (working, just not optimal)
- No new feature categories (sentiment, temporal, regime)

## Notes

**Design decisions:**
- pandas-ta chosen over TA-Lib for ease of installation (pure Python vs C libraries)
- Alternative.me chosen over Twitter API (no approval delays, free access)
- NYSE calendar used for temporal features (most common reference)
- 2-regime HMM for volatility (low/high states, simpler than 3+ regimes)
- merge_asof(direction='backward') prevents look-ahead bias in sentiment alignment
- Daily caching for sentiment API (prevents excessive calls, data updates daily anyway)

**Known limitations:**
- Microstructure features (order book) only available during live trading (CCXT doesn't provide historical order books)
- HMM requires 100+ candles for stable fitting (insufficient data warning logged)
- Sentiment data granularity is daily (Fear & Greed Index updates once per day)
- Temporal features assume crypto trading (24/7 markets, NYSE calendar for reference only)

**Future enhancements** (out of scope for Phase 5):
- Streaming sentiment updates (WebSocket integration)
- Historical order book reconstruction (if exchange provides)
- Multi-timeframe HMM (5m, 15m, 1h regimes)
- Twitter sentiment integration (requires API approval)

---

**Plan created:** 2025-12-27
**Plan scope:** 3 tasks, ~45% context
**Checkpoint types:** 3 auto (all tasks can proceed without user input)
**Ready for execution:** Yes (YOLO mode enabled)

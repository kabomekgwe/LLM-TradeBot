---
phase: 02-complete-agent-implementations
plan: 02
type: execute
---

<objective>
Integrate LightGBM ML model for price predictions in PredictAgent.

Purpose: Replace hardcoded 0.0 confidence with machine learning-based predictions using QuantAnalyst indicator features.
Output: Working ML prediction pipeline with trained model and real confidence scores.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-complete-agent-implementations/DISCOVERY.md
@.planning/phases/02-complete-agent-implementations/02-01-SUMMARY.md

**Codebase constraints:**
- Python 3.7+ with asyncio
- LightGBM library already in requirements.txt
- Agent pattern: `async def execute(context) -> dict`
- Context contains QuantAnalyst indicators from Plan 02-01
- Model storage: `trading/ml/models/` directory (should be added to .gitignore)

**From codebase analysis (CONCERNS.md):**
- **Current issue**: PredictAgent returns hardcoded neutral 0.0 confidence (`trading/agents/predict.py:18,57`)
- **Impact**: Ensemble voting lacks ML-based prediction, reducing decision quality

**From DISCOVERY.md:**
- LightGBM training requires: features (X_train), labels (y_train), Dataset wrapper
- Training params: binary classification, early stopping, validation set
- Prediction: Load model, extract features, predict probability
- Model persistence: Save/load with `bst.save_model()` / `lgb.Booster(model_file=...)`
- Feature engineering: Use QuantAnalyst indicators (RSI, MACD, Bollinger Bands)

**Prior work:**
- Plan 02-01 completed - QuantAnalystAgent now returns real TA-Lib indicators
- Phase 1 established .gitignore (add ml/models/ to prevent committing trained models)

**Why this matters:**
The PredictAgent provides ML-based forecasts that complement the adversarial Bull/Bear analysis. Without a trained model, the entire ensemble voting system operates on adversarial opinions alone, missing the quantitative prediction component.
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create LightGBM training script</name>
  <files>trading/ml/train_lightgbm.py, trading/ml/models/.gitkeep, .gitignore</files>
  <action>
Create standalone training script that fetches historical data and trains initial model.

**1. Create `trading/ml/train_lightgbm.py`:**
```python
"""
LightGBM Model Training Script
Trains price direction prediction model using historical OHLCV data and technical indicators.
"""

import asyncio
import numpy as np
import lightgbm as lgb
import talib
from trading.providers.factory import ExchangeProviderFactory
from trading.config import TradingConfig
import os

async def fetch_historical_data(symbol: str, limit: int = 1000):
    """Fetch historical OHLCV data for training."""
    config = TradingConfig.from_env()  # Load from environment
    provider = ExchangeProviderFactory.create(config)

    # Fetch historical 5m candles
    ohlcv = await provider.fetch_ohlcv(symbol, timeframe='5m', limit=limit)
    return ohlcv

def calculate_features(ohlcv):
    """Calculate technical indicator features from OHLCV data."""
    close = np.array([float(candle.close) for candle in ohlcv])

    # TA-Lib indicators (same as QuantAnalystAgent)
    rsi = talib.RSI(close, timeperiod=14)
    macd, macdsignal, macdhist = talib.MACD(close, fastperiod=12, slowperiod=26, signalperiod=9)
    upperband, middleband, lowerband = talib.BBANDS(close, timeperiod=20, nbdevup=2, nbdevdn=2, matype=0)

    # Price momentum features
    returns = np.diff(close) / close[:-1]
    returns = np.append(0, returns)  # Prepend 0 for alignment

    # Combine features
    features = np.column_stack([
        rsi,
        macd,
        macdsignal,
        macdhist,
        upperband,
        middleband,
        lowerband,
        returns
    ])

    return features

def create_labels(ohlcv, lookahead: int = 5):
    """Create binary labels: 1 if price goes up in next N candles, 0 otherwise."""
    close = np.array([float(candle.close) for candle in ohlcv])
    labels = np.zeros(len(close))

    for i in range(len(close) - lookahead):
        future_price = close[i + lookahead]
        current_price = close[i]
        labels[i] = 1 if future_price > current_price else 0

    # Last lookahead candles can't have labels (no future data)
    return labels[:-lookahead]

async def main():
    symbol = "BTC/USDT"
    print(f"Fetching historical data for {symbol}...")

    # Fetch historical data
    ohlcv = await fetch_historical_data(symbol, limit=1000)
    print(f"Fetched {len(ohlcv)} candles")

    # Calculate features
    features = calculate_features(ohlcv)
    labels = create_labels(ohlcv, lookahead=5)

    # Remove NaN rows (early periods lack indicator data)
    valid_mask = ~np.isnan(features).any(axis=1)
    features = features[valid_mask]
    labels = labels[valid_mask[:len(labels)]]  # Labels are shorter due to lookahead

    # Align features and labels
    min_len = min(len(features), len(labels))
    features = features[:min_len]
    labels = labels[:min_len]

    print(f"Training samples: {len(features)} (after removing NaN)")

    # Split train/validation (80/20)
    split_idx = int(len(features) * 0.8)
    X_train, X_val = features[:split_idx], features[split_idx:]
    y_train, y_val = labels[:split_idx], labels[split_idx:]

    # Create LightGBM datasets
    train_data = lgb.Dataset(X_train, label=y_train)
    val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)

    # Training parameters
    params = {
        'objective': 'binary',
        'metric': 'binary_logloss',
        'boosting_type': 'gbdt',
        'num_leaves': 31,
        'learning_rate': 0.05,
        'feature_fraction': 0.9,
        'verbose': -1
    }

    print("Training LightGBM model...")
    bst = lgb.train(
        params,
        train_data,
        num_boost_round=1000,
        valid_sets=[val_data],
        callbacks=[lgb.early_stopping(stopping_rounds=50)]
    )

    # Save model
    os.makedirs('trading/ml/models', exist_ok=True)
    model_path = 'trading/ml/models/lgbm_predictor.txt'
    bst.save_model(model_path)
    print(f"Model saved to {model_path}")
    print(f"Best iteration: {bst.best_iteration}")

if __name__ == "__main__":
    asyncio.run(main())
```

**2. Update `.gitignore`** to exclude trained models:
```
# ML Models (large binary files, regenerated via training)
trading/ml/models/*.txt
trading/ml/models/*.bin
```

**3. Create `.gitkeep`** in models directory:
```bash
mkdir -p trading/ml/models
touch trading/ml/models/.gitkeep
```

**What to avoid:**
- Don't commit trained models (add to .gitignore, they're large and environment-specific)
- Don't use pandas if not necessary (numpy is sufficient for this task)
- Don't skip NaN removal (will cause LightGBM errors)
- Don't hardcode symbol (use parameter for flexibility, default to BTC/USDT)

**Why these choices:**
- Standalone script: Easy to run separately for retraining
- Binary classification: Simpler than regression, sufficient for directional prediction
- 5-candle lookahead: Balances prediction horizon with signal quality
- Early stopping: Prevents overfitting, reduces training time
  </action>
  <verify>
1. Script runs: `python trading/ml/train_lightgbm.py` completes without errors
2. Model file created: `trading/ml/models/lgbm_predictor.txt` exists
3. .gitignore updated: `git status` shows models directory but not .txt files
4. Model loads: `python -c "import lightgbm as lgb; lgb.Booster(model_file='trading/ml/models/lgbm_predictor.txt')"` succeeds
  </verify>
  <done>
- Training script created and functional
- Initial model trained on BTC/USDT historical data
- Model saved to trading/ml/models/
- Models excluded from git tracking
- Script can be re-run for periodic retraining
  </done>
</task>

<task type="auto">
  <name>Task 2: Integrate trained model in PredictAgent</name>
  <files>trading/agents/predict.py</files>
  <action>
Replace hardcoded 0.0 confidence with real LightGBM predictions using features from QuantAnalystAgent.

**1. Load model at initialization:**
```python
import lightgbm as lgb
import numpy as np
import os

class PredictAgent(BaseAgent):
    def __init__(self, config):
        super().__init__(config)

        # Load pre-trained LightGBM model
        model_path = 'trading/ml/models/lgbm_predictor.txt'
        if os.path.exists(model_path):
            self.model = lgb.Booster(model_file=model_path)
            self.logger.info(f"Loaded LightGBM model from {model_path}")
        else:
            self.model = None
            self.logger.warning(f"No trained model found at {model_path}. Run train_lightgbm.py first.")
```

**2. Extract features from context in execute():**
```python
async def execute(self, context):
    # Fallback if no model trained
    if not self.model:
        return {
            'prediction': 0.0,
            'confidence': 0.0,
            'reason': 'No trained model available'
        }

    # Get indicators from QuantAnalystAgent
    indicators = context.get('quant_analyst', {}).get('indicators', {})
    if not indicators:
        return {
            'prediction': 0.0,
            'confidence': 0.0,
            'reason': 'No indicator data from QuantAnalyst'
        }

    # Extract features (must match training feature order)
    try:
        features = np.array([[
            indicators['rsi']['value'],
            indicators['macd']['macd'],
            indicators['macd']['signal'],
            indicators['macd']['histogram'],
            indicators['bollinger']['upper'],
            indicators['bollinger']['middle'],
            indicators['bollinger']['lower'],
            0.0  # Price returns placeholder (calculate if needed)
        ]])
    except (KeyError, TypeError) as e:
        self.logger.error(f"Feature extraction failed: {e}")
        return {
            'prediction': 0.0,
            'confidence': 0.0,
            'reason': f'Feature extraction error: {e}'
        }
```

**3. Make prediction:**
```python
    # Predict probability of price going up
    prob_up = self.model.predict(features, num_iteration=self.model.best_iteration)[0]

    # Convert to direction and confidence
    # prob_up in [0, 1], where >0.5 means price will go up
    direction = 1 if prob_up > 0.5 else -1
    confidence = abs(prob_up - 0.5) * 2  # Scale to [0, 1]: confidence in prediction

    return {
        'prediction': direction,  # 1 = bullish, -1 = bearish
        'confidence': confidence,  # [0, 1] confidence score
        'probability_up': prob_up,  # Raw probability for transparency
        'reason': f'ML prediction: {prob_up:.2%} up, conf={confidence:.2f}'
    }
```

**What to avoid:**
- Don't proceed if model fails to load (return neutral fallback)
- Don't mismatch feature order (must match training script exactly)
- Don't ignore KeyError when extracting features (handle gracefully)
- Don't use model without checking best_iteration (use early stopping result)

**Why these choices:**
- Fail-safe fallback: System still works if model not trained
- Feature extraction from context: Uses QuantAnalyst outputs (Plan 02-01)
- Probability to confidence: abs(p - 0.5) * 2 scales to intuitive 0-1 range
- Transparency: Return raw probability for debugging and logging
  </action>
  <verify>
1. Model loads: Check logs for "Loaded LightGBM model" message
2. No model fallback: Delete model file temporarily, verify agent returns neutral 0.0
3. Real predictions: Run with model present, verify confidence != 0.0
4. Feature extraction: Add logging to verify features match [rsi, macd, signal, hist, upper, middle, lower, returns]
  </verify>
  <done>
- PredictAgent no longer returns hardcoded 0.0 confidence
- Loads trained LightGBM model at initialization
- Extracts features from QuantAnalyst indicators
- Returns real ML-based predictions with confidence scores
- Graceful fallback if model missing or feature extraction fails
  </done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] Training script runs successfully
- [ ] Model file created in trading/ml/models/
- [ ] Models excluded from git (check .gitignore)
- [ ] PredictAgent loads model without errors
- [ ] PredictAgent returns non-zero confidence with real predictions
- [ ] Feature extraction matches training feature order
- [ ] Fallback works when model missing
</verification>

<success_criteria>

- Both tasks completed successfully
- LightGBM model trained on historical data
- PredictAgent returns ML-based predictions
- No hardcoded 0.0 confidence values
- System gracefully handles missing model
- Ready for Plan 02-03 (Bull/Bear agent enhancement)
</success_criteria>

<output>
After completion, create `.planning/phases/02-complete-agent-implementations/02-02-SUMMARY.md`:

# Phase 2 Plan 2: LightGBM Integration Summary

**[One-liner describing what shipped]**

## Accomplishments

- Created LightGBM training script for price direction prediction
- Integrated trained model in PredictAgent for real ML predictions
- [Additional accomplishments]

## Files Created/Modified

- `trading/ml/train_lightgbm.py` - Training script for initial model
- `trading/agents/predict.py` - Integrated LightGBM predictions
- `.gitignore` - Excluded ML models from tracking
- `trading/ml/models/.gitkeep` - Placeholder for model directory

## Decisions Made

- Binary classification (price up/down) vs regression (returns prediction)
- 5-candle lookahead for label creation
- Feature set: RSI, MACD components, Bollinger Bands, price returns
- Early stopping with 50 rounds patience

## Deviations from Plan

[Document any deviations using deviation rules, or "None"]

## Issues Encountered

[Problems and resolutions, or "None"]

## Verification Results

[Results of verification checklist]

## Next Step

Ready for 02-03-PLAN.md (Bull/Bear Agent Enhancement)
</output>

# Phase 12 Plan 02: Secrets Management & Structured Logging

**Goal**: Implement Docker secrets for API key management and structured JSON logging for production debugging

**Context References**:
- @12-CONTEXT.md - User vision for Phase 12
- @12-01-PLAN.md - Database and model serving (Plan 01)
- @STATE.md - Project state and prior decisions

**Scope**: 3 tasks, ~800 LOC, 35% context usage

**Prerequisites**:
- Phase 11 Docker infrastructure complete
- Plan 12-01 database and model serving complete
- `python-json-logger>=2.0.0` already in requirements.txt

---

## Task 1: Docker Secrets Configuration

**Type**: `implement`

**Files to create**:
- `secrets/exchange_api_key` - API key secret file (gitignored)
- `secrets/exchange_api_secret` - API secret file (gitignored)
- `secrets/kill_switch_secret` - Kill switch secret file (gitignored)
- `secrets/db_password` - Database password secret file (gitignored)
- `secrets/.gitkeep` - Keep directory in git

**Files to modify**:
- `docker-compose.yml` - Add secrets configuration
- `.gitignore` - Ignore secrets/* except .gitkeep
- `docs/DEPLOYMENT.md` - Add secrets management section

**Action**:
Configure Docker secrets in `docker-compose.yml`:

```yaml
# docker-compose.yml (add at top level)
secrets:
  exchange_api_key:
    file: ./secrets/exchange_api_key
  exchange_api_secret:
    file: ./secrets/exchange_api_secret
  kill_switch_secret:
    file: ./secrets/kill_switch_secret
  db_password:
    file: ./secrets/db_password

services:
  trading-bot:
    # ... existing config ...
    secrets:
      - exchange_api_key
      - exchange_api_secret
      - kill_switch_secret
      - db_password
    environment:
      # Secrets are mounted at /run/secrets/<secret_name>
      EXCHANGE_API_KEY_FILE: /run/secrets/exchange_api_key
      EXCHANGE_API_SECRET_FILE: /run/secrets/exchange_api_secret
      KILL_SWITCH_SECRET_FILE: /run/secrets/kill_switch_secret
      # Override DATABASE_URL to use secret
      DATABASE_URL: postgresql://tradingbot:$(cat /run/secrets/db_password)@postgres:5432/tradingbot

  dashboard:
    # ... existing config ...
    secrets:
      - kill_switch_secret
      - db_password
    environment:
      KILL_SWITCH_SECRET_FILE: /run/secrets/kill_switch_secret
      DATABASE_URL: postgresql://tradingbot:$(cat /run/secrets/db_password)@postgres:5432/tradingbot

  postgres:
    # ... existing config ...
    secrets:
      - db_password
    environment:
      POSTGRES_PASSWORD_FILE: /run/secrets/db_password
```

Create `.gitignore` entries:
```
# Secrets
secrets/*
!secrets/.gitkeep
```

Create deployment script for secrets initialization:

```bash
# scripts/init-secrets.sh
#!/bin/bash
set -e

SECRETS_DIR="./secrets"
mkdir -p "$SECRETS_DIR"

echo "=== Docker Secrets Initialization ==="
echo

# Exchange API credentials
if [ ! -f "$SECRETS_DIR/exchange_api_key" ]; then
    read -p "Enter Exchange API Key: " API_KEY
    echo -n "$API_KEY" > "$SECRETS_DIR/exchange_api_key"
    chmod 600 "$SECRETS_DIR/exchange_api_key"
    echo "✓ Created exchange_api_key"
else
    echo "✓ exchange_api_key already exists"
fi

if [ ! -f "$SECRETS_DIR/exchange_api_secret" ]; then
    read -p "Enter Exchange API Secret: " API_SECRET
    echo -n "$API_SECRET" > "$SECRETS_DIR/exchange_api_secret"
    chmod 600 "$SECRETS_DIR/exchange_api_secret"
    echo "✓ Created exchange_api_secret"
else
    echo "✓ exchange_api_secret already exists"
fi

# Kill switch secret
if [ ! -f "$SECRETS_DIR/kill_switch_secret" ]; then
    KILL_SWITCH_SECRET=$(openssl rand -base64 32)
    echo -n "$KILL_SWITCH_SECRET" > "$SECRETS_DIR/kill_switch_secret"
    chmod 600 "$SECRETS_DIR/kill_switch_secret"
    echo "✓ Generated kill_switch_secret: $KILL_SWITCH_SECRET"
else
    echo "✓ kill_switch_secret already exists"
fi

# Database password
if [ ! -f "$SECRETS_DIR/db_password" ]; then
    DB_PASSWORD=$(openssl rand -base64 32)
    echo -n "$DB_PASSWORD" > "$SECRETS_DIR/db_password"
    chmod 600 "$SECRETS_DIR/db_password"
    echo "✓ Generated db_password: $DB_PASSWORD"
else
    echo "✓ db_password already exists"
fi

echo
echo "=== Secrets initialized successfully ==="
echo "Secret files created in: $SECRETS_DIR"
echo "File permissions set to 600 (owner read/write only)"
echo
echo "IMPORTANT: Never commit secrets/* to version control!"
```

**Verify**:
```bash
# Initialize secrets
chmod +x scripts/init-secrets.sh
./scripts/init-secrets.sh

# Verify secret files created
ls -lah secrets/
# Should show 4 files with 600 permissions

# Verify secrets mounted in container
docker-compose up -d
docker exec llm-tradebot-trading-bot-1 ls -la /run/secrets/
docker exec llm-tradebot-trading-bot-1 cat /run/secrets/exchange_api_key

# Verify secrets not in git
git status | grep secrets/
# Should only show secrets/.gitkeep
```

**Done**: Docker secrets configured with secure file permissions and automated initialization

---

## Task 2: Migrate API Keys to Secrets

**Type**: `implement`

**Files to create**:
- `trading/config/secrets.py` - Secrets loading utility

**Files to modify**:
- `trading/config/config.py` - Use secrets instead of environment variables
- `trading/exchange/exchange_client.py` - Load credentials from secrets
- `trading/safety/kill_switch.py` - Load kill switch secret from file

**Action**:
Create secrets loader utility:

```python
# trading/config/secrets.py
import os
from pathlib import Path
from typing import Optional
import logging

logger = logging.getLogger(__name__)

class SecretsManager:
    """Load secrets from Docker secrets or fallback to environment variables."""

    SECRETS_DIR = Path("/run/secrets")

    @classmethod
    def get_secret(cls, secret_name: str, env_var_name: Optional[str] = None) -> Optional[str]:
        """
        Load secret from Docker secrets file or environment variable.

        Args:
            secret_name: Name of the secret file (e.g., 'exchange_api_key')
            env_var_name: Fallback environment variable name (e.g., 'EXCHANGE_API_KEY')

        Returns:
            Secret value or None if not found
        """
        # Try Docker secrets first
        secret_path = cls.SECRETS_DIR / secret_name
        if secret_path.exists():
            try:
                secret_value = secret_path.read_text().strip()
                logger.info(f"Loaded secret from Docker secrets: {secret_name}")
                return secret_value
            except Exception as e:
                logger.error(f"Failed to read secret {secret_name}: {e}")

        # Fallback to environment variable
        if env_var_name:
            env_value = os.getenv(env_var_name)
            if env_value:
                logger.warning(f"Using environment variable {env_var_name} (Docker secrets not available)")
                return env_value

        logger.error(f"Secret {secret_name} not found in Docker secrets or environment variables")
        return None

    @classmethod
    def get_exchange_credentials(cls) -> tuple[Optional[str], Optional[str]]:
        """Load exchange API key and secret."""
        api_key = cls.get_secret("exchange_api_key", "EXCHANGE_API_KEY")
        api_secret = cls.get_secret("exchange_api_secret", "EXCHANGE_API_SECRET")
        return api_key, api_secret

    @classmethod
    def get_kill_switch_secret(cls) -> Optional[str]:
        """Load kill switch secret for HMAC authentication."""
        return cls.get_secret("kill_switch_secret", "KILL_SWITCH_SECRET")

    @classmethod
    def get_db_password(cls) -> Optional[str]:
        """Load database password."""
        return cls.get_secret("db_password", "DB_PASSWORD")
```

Update exchange client to use secrets:

```python
# trading/exchange/exchange_client.py (modify initialization)
from ..config.secrets import SecretsManager

class ExchangeClient:
    def __init__(self, exchange_id: str = "binance", testnet: bool = True):
        # Load credentials from Docker secrets
        api_key, api_secret = SecretsManager.get_exchange_credentials()

        if not api_key or not api_secret:
            raise ValueError("Exchange API credentials not found in secrets or environment")

        # ... rest of initialization with api_key and api_secret ...
```

Update kill switch to use secrets:

```python
# trading/safety/kill_switch.py (modify initialization)
from ..config.secrets import SecretsManager

class KillSwitch:
    def __init__(self):
        # Load secret from Docker secrets
        self.secret = SecretsManager.get_kill_switch_secret()

        if not self.secret:
            raise ValueError("Kill switch secret not found in secrets or environment")

        # ... rest of initialization ...
```

**Verify**:
```bash
# Stop containers
docker-compose down

# Remove .env to force secrets usage
mv .env .env.backup

# Start with secrets
docker-compose up -d

# Verify credentials loaded from secrets (check logs)
docker-compose logs trading-bot | grep "Loaded secret"

# Test kill switch with secret
KILL_SWITCH_SECRET=$(cat secrets/kill_switch_secret)
curl -X POST http://localhost:5173/api/v1/safety/kill-switch/activate \
  -H "Content-Type: application/json" \
  -H "X-Kill-Switch-Signature: $(echo -n 'activate' | openssl dgst -sha256 -hmac "$KILL_SWITCH_SECRET" -binary | base64)" \
  -d '{"reason": "Emergency test"}'

# Restore .env for local development
mv .env.backup .env
```

**Done**: API keys loaded from Docker secrets with environment variable fallback

---

## Task 3: Structured JSON Logging

**Type**: `implement`

**Files to create**:
- `trading/logging/json_logger.py` - Structured JSON logging configuration
- `trading/logging/log_context.py` - Request context manager for correlation IDs

**Files to modify**:
- `trading/cli.py` - Initialize structured logging on startup
- `trading/manager.py` - Add correlation IDs to trade logs
- `trading/web/server.py` - Add request ID middleware

**Action**:
Create JSON logger configuration:

```python
# trading/logging/json_logger.py
import logging
import sys
from pythonjsonlogger import jsonlogger
from typing import Optional

class CustomJsonFormatter(jsonlogger.JsonFormatter):
    """Custom JSON formatter with additional fields."""

    def add_fields(self, log_record, record, message_dict):
        """Add custom fields to log records."""
        super().add_fields(log_record, record, message_dict)

        # Add timestamp in ISO format
        log_record['timestamp'] = self.formatTime(record, self.datefmt)

        # Add log level
        log_record['level'] = record.levelname

        # Add logger name
        log_record['logger'] = record.name

        # Add correlation ID if present
        if hasattr(record, 'correlation_id'):
            log_record['correlation_id'] = record.correlation_id

        # Add trade context if present
        if hasattr(record, 'symbol'):
            log_record['symbol'] = record.symbol
        if hasattr(record, 'trade_id'):
            log_record['trade_id'] = record.trade_id

def setup_json_logging(log_level: str = "INFO"):
    """Configure structured JSON logging for production."""
    formatter = CustomJsonFormatter(
        fmt='%(timestamp)s %(level)s %(name)s %(message)s',
        datefmt='%Y-%m-%dT%H:%M:%S'
    )

    # Console handler (stdout for Docker logs)
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setFormatter(formatter)

    # File handler (optional, for persistent logs)
    file_handler = logging.FileHandler('logs/trading.json.log')
    file_handler.setFormatter(formatter)

    # Root logger configuration
    root_logger = logging.getLogger()
    root_logger.setLevel(getattr(logging, log_level.upper()))
    root_logger.addHandler(console_handler)
    root_logger.addHandler(file_handler)

    # Suppress noisy third-party loggers
    logging.getLogger('ccxt').setLevel(logging.WARNING)
    logging.getLogger('urllib3').setLevel(logging.WARNING)

    logging.info("Structured JSON logging initialized", extra={'log_level': log_level})
```

Create correlation ID context manager:

```python
# trading/logging/log_context.py
import logging
import uuid
from contextvars import ContextVar

# Context variable for correlation ID
correlation_id_var: ContextVar[Optional[str]] = ContextVar('correlation_id', default=None)

class LogContext:
    """Manage logging context with correlation IDs."""

    @staticmethod
    def set_correlation_id(correlation_id: str):
        """Set correlation ID for current context."""
        correlation_id_var.set(correlation_id)

    @staticmethod
    def get_correlation_id() -> Optional[str]:
        """Get correlation ID from current context."""
        return correlation_id_var.get()

    @staticmethod
    def generate_correlation_id() -> str:
        """Generate new correlation ID."""
        return str(uuid.uuid4())

class CorrelationFilter(logging.Filter):
    """Add correlation ID to log records."""

    def filter(self, record):
        correlation_id = LogContext.get_correlation_id()
        if correlation_id:
            record.correlation_id = correlation_id
        return True
```

Add request ID middleware to FastAPI:

```python
# trading/web/server.py (add middleware)
from starlette.middleware.base import BaseHTTPMiddleware
from ..logging.log_context import LogContext

class RequestIDMiddleware(BaseHTTPMiddleware):
    """Add unique request ID to each API request."""

    async def dispatch(self, request, call_next):
        # Generate correlation ID for this request
        correlation_id = LogContext.generate_correlation_id()
        LogContext.set_correlation_id(correlation_id)

        # Add to response headers for debugging
        response = await call_next(request)
        response.headers["X-Request-ID"] = correlation_id

        return response

# Add middleware
app.add_middleware(RequestIDMiddleware)
```

Initialize logging on startup:

```python
# trading/cli.py (modify main)
from .logging.json_logger import setup_json_logging
from .logging.log_context import CorrelationFilter
import logging

def main():
    # Initialize structured logging
    log_level = os.getenv('LOG_LEVEL', 'INFO')
    setup_json_logging(log_level)

    # Add correlation filter to all loggers
    correlation_filter = CorrelationFilter()
    for handler in logging.root.handlers:
        handler.addFilter(correlation_filter)

    # ... rest of CLI initialization ...
```

Add trade context to manager logs:

```python
# trading/manager.py (modify trade execution logging)
def execute_trade(self, decision: TradingDecision):
    # Generate correlation ID for this trade
    correlation_id = LogContext.generate_correlation_id()
    LogContext.set_correlation_id(correlation_id)

    self.logger.info(
        "Executing trade",
        extra={
            'symbol': decision.symbol,
            'action': decision.action.value,
            'confidence': decision.confidence
        }
    )

    # ... trade execution logic ...
```

**Verify**:
```bash
# Start with JSON logging
docker-compose up -d

# Execute trade and verify JSON logs
docker-compose logs trading-bot | tail -50 | grep "Executing trade"
# Should see JSON formatted logs with correlation_id, symbol, timestamp

# Verify log file created
docker exec llm-tradebot-trading-bot-1 ls -lah logs/
cat logs/trading.json.log | tail -10

# Test API request correlation
curl http://localhost:5173/api/v1/ml/models -v 2>&1 | grep "X-Request-ID"
# Should see correlation ID in response headers

# Query logs by correlation ID
CORRELATION_ID=$(docker-compose logs trading-bot | grep "correlation_id" | head -1 | jq -r '.correlation_id')
docker-compose logs trading-bot | jq "select(.correlation_id == \"$CORRELATION_ID\")"
```

**Done**: Structured JSON logging with correlation IDs for production debugging

---

## Success Criteria

- [ ] Docker secrets configured for API keys, kill switch, and database password
- [ ] Secrets initialization script working with secure file permissions
- [ ] Trading bot loads credentials from Docker secrets with .env fallback
- [ ] Structured JSON logs written to stdout and file with correlation IDs
- [ ] API requests include `X-Request-ID` header for tracing
- [ ] All logs queryable by correlation ID using `jq`
- [ ] Secrets never committed to git (verified with `git status`)

## Checkpoints

- **After Task 1** (human-verify): Verify secrets mounted in containers at `/run/secrets/`
- **After Task 3** (human-verify): Verify JSON logs with correlation IDs in `docker logs`

---

**Dependencies**:
- Plan 12-01 must be completed first (database infrastructure)
- `python-json-logger>=2.0.0` already in requirements.txt

---

*Phase: 12-model-serving-data-infrastructure*
*Plan: 12-02*
*Created: 2025-12-28*

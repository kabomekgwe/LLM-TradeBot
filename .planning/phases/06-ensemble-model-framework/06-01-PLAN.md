# Phase 6 Execution Plan: Ensemble Model Framework

**Plan:** 06-01-ensemble-model-framework
**Phase:** 6 of 8 (Ensemble Model Framework)
**Created:** 2025-12-27
**Context:** [06-CONTEXT.md](06-CONTEXT.md) | [06-RESEARCH.md](06-RESEARCH.md)

---

## Plan Overview

Implement a production-ready ensemble model framework that combines LightGBM, XGBoost, and Random Forest with regime-aware strategy switching. The system automatically selects the optimal ensemble strategy (voting, stacking, or dynamic selection) based on volatility regimes detected by Phase 5's HMM detector.

**Success criteria (all three non-negotiable):**
1. ✅ Ensemble predictions are 10-20% more accurate than single LightGBM
2. ✅ Clean abstraction for adding/removing models (extensible architecture)
3. ✅ Regime-aware strategy switching works correctly (bug-free pipeline)

---

## Tasks

### Task 1: Install XGBoost and Create Ensemble Base Infrastructure
**Checkpoint:** auto
**Estimated complexity:** Medium

**What:**
Install XGBoost dependency and create the foundational ensemble infrastructure with clean abstractions for multiple models and strategies.

**Why:**
XGBoost is the only missing dependency. The base infrastructure establishes the extensible architecture required for Task 1's success criteria (clean abstraction for adding/removing models).

**How:**
1. Add `xgboost` to `requirements.txt`
2. Run `pip install xgboost` to install dependency
3. Create `trading/ml/ensemble/` directory structure:
   ```
   trading/ml/ensemble/
   ├── __init__.py
   ├── base_ensemble.py       # Abstract base class for ensemble strategies
   ├── voting_ensemble.py     # VotingClassifier wrapper
   ├── stacking_ensemble.py   # StackingClassifier wrapper
   ├── model_registry.py      # Clean abstraction for model management
   └── persistence.py         # Security-hardened model serialization
   ```
4. Implement `BaseEnsemble` abstract class:
   - Abstract methods: `fit()`, `predict()`, `predict_proba()`
   - Common functionality: logging, error handling, feature validation
5. Implement `ModelRegistry` class for clean model management:
   - Methods: `register_model()`, `remove_model()`, `get_models()`, `get_model()`
   - Validates model has required methods (`fit`, `predict`, `predict_proba`)
   - Makes it trivial to add/remove models (extensibility requirement)
6. Implement `EnsemblePersistence` class (SECURITY HARDENED):
   - **XGBoost:** Native JSON format ONLY (`model.save_model('file.json')`)
   - **LightGBM:** Native text format ONLY (`booster_.save_model('file.txt')`)
   - **Random Forest:** joblib (standard sklearn practice, acceptable)
   - **CRITICAL:** No unsafe serialization for XGBoost/LightGBM
   - Save metadata using JSON format (versions, feature names, training date)

**Security Requirements (NON-NEGOTIABLE):**
- XGBoost models MUST use native JSON format (no unsafe alternatives)
- LightGBM models MUST use native text format (no unsafe alternatives)
- Metadata MUST be saved in JSON format (human-readable, safe)
- Random Forest uses joblib (sklearn standard, only acceptable case)

**Files to create:**
- `trading/ml/ensemble/__init__.py`
- `trading/ml/ensemble/base_ensemble.py`
- `trading/ml/ensemble/voting_ensemble.py`
- `trading/ml/ensemble/stacking_ensemble.py`
- `trading/ml/ensemble/model_registry.py`
- `trading/ml/ensemble/persistence.py`

**Files to modify:**
- `requirements.txt` (add xgboost)

**Verification:**
```bash
# 1. Check XGBoost installed
python -c "import xgboost as xgb; print(f'XGBoost version: {xgb.__version__}')"

# 2. Check ensemble infrastructure imports
python -c "
from trading.ml.ensemble.base_ensemble import BaseEnsemble
from trading.ml.ensemble.model_registry import ModelRegistry
from trading.ml.ensemble.persistence import EnsemblePersistence
print('✅ Ensemble infrastructure imports successfully')
"

# 3. Test ModelRegistry extensibility
python -c "
from trading.ml.ensemble.model_registry import ModelRegistry
import lightgbm as lgb

registry = ModelRegistry()
registry.register_model('lgbm', lgb.LGBMClassifier())
registry.register_model('test', lgb.LGBMClassifier())
registry.remove_model('test')
assert 'lgbm' in registry.get_models()
assert 'test' not in registry.get_models()
print('✅ ModelRegistry extensibility works')
"

# 4. Verify security-hardened persistence (JSON/text formats only)
python -c "
from trading.ml.ensemble.persistence import EnsemblePersistence
import inspect

# Check that save_models method uses native formats
source = inspect.getsource(EnsemblePersistence.save_models)
assert 'save_model' in source, 'Must use native save_model for XGBoost/LightGBM'
assert 'JSON' in source or 'json' in source, 'Must mention JSON format'
print('✅ Persistence uses security-hardened formats')
"
```

---

### Task 2: Implement Regime-Aware Ensemble with Three Models
**Checkpoint:** auto
**Estimated complexity:** High

**What:**
Implement the regime-aware ensemble that integrates LightGBM, XGBoost, and Random Forest, automatically switching between voting/stacking/dynamic strategies based on Phase 5's HMM volatility regime detector.

**Why:**
This is the core Phase 6 deliverable. The regime-aware strategy switching is the key differentiator (from 06-CONTEXT.md) and directly implements the vision: "Low volatility → Stacking, High volatility → Voting, Transitional → Dynamic selection."

**How:**
1. Create `trading/ml/ensemble/regime_aware_ensemble.py`:
   - Initialize all three models: LightGBM, XGBoost, RandomForestClassifier
   - Create voting ensemble using `sklearn.ensemble.VotingClassifier` (soft voting)
   - Create stacking ensemble using `sklearn.ensemble.StackingClassifier` (cv=5, LogisticRegression meta-model)
   - Implement dynamic selection (track recent performance, select best model)
2. Implement regime-to-strategy mapping logic:
   ```python
   if is_low_volatility and regime_prob > 0.7:
       strategy = 'stacking'  # Meta-model learns combination
   elif regime_prob < 0.6:
       strategy = 'dynamic'   # Transitional regime
   else:
       strategy = 'voting'    # High volatility, robust to noise
   ```
3. Add comprehensive observability (from 06-CONTEXT.md specifics):
   - Log individual model predictions (LightGBM, XGBoost, Random Forest)
   - Log active strategy and reason (e.g., "Using voting - high volatility regime (prob=0.82)")
   - Use Phase 4's DecisionContext for correlation tracking
   - Structured JSON logging for all ensemble decisions
4. Implement feature importance aggregation:
   - Extract `feature_importances_` from all three models
   - Average importance across models (simple aggregation)
   - Return sorted dict of aggregated importance
5. Integrate with Phase 5's regime detector:
   - Accept regime_info dict with keys: `current_regime`, `is_low_volatility`, `regime_prob_0`, `regime_prob_1`
   - Extract from `VolatilityRegimeDetector` output columns
   - Validate regime data before strategy selection

**Files to create:**
- `trading/ml/ensemble/regime_aware_ensemble.py`

**Files to modify:**
- `trading/ml/ensemble/__init__.py` (export RegimeAwareEnsemble)

**Verification:**
```bash
# 1. Test regime-to-strategy mapping
python -c "
from trading.ml.ensemble.regime_aware_ensemble import RegimeAwareEnsemble
import numpy as np

ensemble = RegimeAwareEnsemble(n_estimators=10)  # Small for speed
X_train = np.random.rand(100, 86)  # 86 features from Phase 5
y_train = np.random.randint(0, 2, 100)
ensemble.fit(X_train, y_train)

# Test low volatility → stacking
regime_info = {'current_regime': 0, 'is_low_volatility': 1, 'regime_prob_0': 0.85, 'regime_prob_1': 0.15}
pred, metadata = ensemble.predict_with_regime(X_train[0:1], regime_info)
assert metadata['strategy'] == 'stacking', f\"Expected stacking, got {metadata['strategy']}\"
print('✅ Low volatility → stacking')

# Test high volatility → voting
regime_info = {'current_regime': 1, 'is_low_volatility': 0, 'regime_prob_0': 0.20, 'regime_prob_1': 0.80}
pred, metadata = ensemble.predict_with_regime(X_train[0:1], regime_info)
assert metadata['strategy'] == 'voting', f\"Expected voting, got {metadata['strategy']}\"
print('✅ High volatility → voting')

# Test transitional → dynamic
regime_info = {'current_regime': 0, 'is_low_volatility': 0, 'regime_prob_0': 0.55, 'regime_prob_1': 0.45}
pred, metadata = ensemble.predict_with_regime(X_train[0:1], regime_info)
assert metadata['strategy'] == 'dynamic', f\"Expected dynamic, got {metadata['strategy']}\"
print('✅ Transitional → dynamic')

# Test observability
assert 'lgbm' in metadata['individual_predictions']
assert 'xgb' in metadata['individual_predictions']
assert 'rf' in metadata['individual_predictions']
assert 'reason' in metadata
print('✅ Observability metadata present')
"

# 2. Test feature importance aggregation
python -c "
from trading.ml.ensemble.regime_aware_ensemble import RegimeAwareEnsemble
import numpy as np

ensemble = RegimeAwareEnsemble(n_estimators=10)
X_train = np.random.rand(100, 86)
y_train = np.random.randint(0, 2, 100)
ensemble.fit(X_train, y_train)

feature_names = [f'feature_{i}' for i in range(86)]
importance = ensemble.get_feature_importance(feature_names)

assert len(importance) == 86, f'Expected 86 features, got {len(importance)}'
assert isinstance(importance, dict), 'Expected dict output'
print('✅ Feature importance aggregation works')
"
```

---

### Task 3: Create Training Script and Integrate with PredictAgent
**Checkpoint:** auto
**Estimated complexity:** High

**What:**
Create a training script for the ensemble (using Phase 5's 86 features), train all three models, and integrate the ensemble into PredictAgent to replace the single LightGBM model.

**Why:**
- Training script validates the ensemble works end-to-end with Phase 5's feature engineering pipeline
- PredictAgent integration makes the ensemble available to the trading system
- Benchmarking against single LightGBM proves the 10-20% accuracy improvement (success criteria #1)

**How:**
1. Create `trading/ml/train_ensemble.py`:
   - Import Phase 5's `FeatureEngineer` (86 features)
   - Import Phase 5's `VolatilityRegimeDetector` (regime detection)
   - Fetch historical OHLCV data (e.g., 10,000 candles)
   - Engineer 86 features using existing pipeline
   - Detect volatility regimes for validation
   - Create labels (price direction 5 candles ahead, from Phase 2)
   - Train ensemble using `RegimeAwareEnsemble`
   - Save models using `EnsemblePersistence` (SECURITY HARDENED - native formats only)
   - Benchmark ensemble vs single LightGBM:
     ```python
     # Single model baseline
     lgbm_baseline = lgb.LGBMClassifier(n_estimators=100)
     lgbm_baseline.fit(X_train, y_train)
     baseline_accuracy = accuracy_score(y_test, lgbm_baseline.predict(X_test))

     # Ensemble performance
     ensemble_predictions = []
     for i in range(len(X_test)):
         regime_info = extract_regime_info(df_test.iloc[i])
         pred, _ = ensemble.predict_with_regime(X_test[i:i+1], regime_info)
         ensemble_predictions.append(pred)
     ensemble_accuracy = accuracy_score(y_test, ensemble_predictions)

     improvement = ((ensemble_accuracy - baseline_accuracy) / baseline_accuracy) * 100
     print(f"Ensemble accuracy improvement: {improvement:.1f}%")
     assert improvement >= 10, f"Ensemble improvement too low: {improvement:.1f}%"
     ```
   - Log training summary (accuracy, improvement, feature importance top 10)
2. Modify `trading/agents/predict.py`:
   - Update `__init__()` to load `RegimeAwareEnsemble` instead of single LightGBM
   - Update `execute()` to:
     - Extract regime info from context (Phase 5's regime detector runs in QuantAnalyst)
     - Call `ensemble.predict_with_regime(X, regime_info)`
     - Log individual model predictions + strategy + reason (observability)
     - Return ensemble prediction with metadata
   - Maintain backward compatibility: if ensemble models not found, fall back to neutral

**Security Requirements (NON-NEGOTIABLE):**
- Training script MUST save models using native formats (JSON for XGBoost, text for LightGBM)
- Training script MUST verify saved files are in correct format (not unsafe serialization)
- PredictAgent MUST load models using native formats only

**Files to create:**
- `trading/ml/train_ensemble.py`

**Files to modify:**
- `trading/agents/predict.py`

**Verification:**
```bash
# 1. Train ensemble and verify accuracy improvement
python trading/ml/train_ensemble.py

# Expected output:
# ✅ Trained ensemble with 3 models
# ✅ Baseline LightGBM accuracy: 62.3%
# ✅ Ensemble accuracy: 71.5%
# ✅ Improvement: 14.8% (meets 10-20% target)
# ✅ Models saved to trading/ml/models/ensemble/
# ✅ Top 10 features by aggregated importance: [...]

# 2. Test PredictAgent integration
python -c "
import asyncio
from trading.agents.predict import PredictAgent
from trading.config import TradingConfig
from unittest.mock import AsyncMock

async def test_predict_agent():
    config = TradingConfig.from_env()
    provider = AsyncMock()
    agent = PredictAgent(provider, config)

    # Create context with regime info
    context = {
        'quant_analyst': {
            'indicators': {},  # Would have 86 features from Phase 5
            'regime_info': {
                'current_regime': 0,
                'is_low_volatility': 1,
                'regime_prob_0': 0.85,
                'regime_prob_1': 0.15
            }
        }
    }

    result = await agent.execute(context)
    ml_pred = result['ml_prediction']

    assert 'direction' in ml_pred
    assert 'confidence' in ml_pred
    assert 'strategy' in ml_pred  # New: ensemble strategy
    assert 'individual_predictions' in ml_pred  # New: observability
    print('✅ PredictAgent ensemble integration works')

asyncio.run(test_predict_agent())
"

# 3. CRITICAL SECURITY VERIFICATION: Check model file formats
ls -la trading/ml/models/ensemble/

# Expected files (SECURITY HARDENED):
# xgboost_model.json        (JSON format - safe, human-readable)
# lightgbm_model.txt        (text format - safe, human-readable)
# random_forest_model.joblib (joblib for sklearn - standard practice)
# metadata.json             (JSON format - safe, human-readable)

# Verify XGBoost is JSON (NOT unsafe serialization)
file trading/ml/models/ensemble/xgboost_model.json
# Expected output: "JSON data" or "ASCII text" (safe format)

# Verify LightGBM is text (NOT unsafe serialization)
file trading/ml/models/ensemble/lightgbm_model.txt
# Expected output: "ASCII text" (safe format)

# Verify metadata is JSON (NOT unsafe serialization)
file trading/ml/models/ensemble/metadata.json
# Expected output: "JSON data" or "ASCII text" (safe format)

# FAILURE CONDITION: If any file shows as serialized data (unsafe), ABORT and fix
```

---

## Dependencies

**Depends on:**
- Phase 5: Enhanced Feature Engineering (86 features, regime detector)
- Phase 4: Decision Transparency & Error Handling (structured logging, DecisionContext)
- Phase 2: Complete Agent Implementations (PredictAgent exists)

**Blocks:**
- Phase 7: Deep Learning Models (will integrate with ensemble framework)
- Phase 8: Model Evaluation & Backtesting (will benchmark ensemble performance)

---

## Risks & Mitigations

| Risk | Likelihood | Impact | Mitigation |
|------|------------|--------|------------|
| Ensemble doesn't improve accuracy 10-20% | Medium | High | Benchmark during Task 3, adjust hyperparameters or model selection if needed |
| Model correlation too high (lack of diversity) | Low | Medium | Research showed LightGBM/XGBoost/RF have complementary strengths, but validate correlation < 0.8 |
| Regime detection bugs break strategy switching | Low | High | Add unit tests for regime validation (probabilities sum to 1, regime matches max prob) |
| XGBoost/LightGBM version incompatibility | Low | Medium | Pin versions in requirements.txt, use native formats (guaranteed compatibility) |
| Training time too long | Low | Low | Use reasonable defaults (100 estimators), focus on architecture not hyperparameter tuning |
| Security vulnerability from unsafe serialization | ELIMINATED | Critical | MANDATORY native formats (JSON/text), verification in Task 3 |

---

## Success Criteria Validation

After completing all tasks, verify success criteria from 06-CONTEXT.md:

### 1. Ensemble predictions are more accurate than single models ✅
```bash
# Run training script, check output
python trading/ml/train_ensemble.py | grep "Improvement:"
# Expected: "Improvement: X.X%" where X.X >= 10.0
```

### 2. Clean abstraction for adding/removing models ✅
```python
# Test extensibility: add/remove models easily
from trading.ml.ensemble.regime_aware_ensemble import RegimeAwareEnsemble
from trading.ml.ensemble.model_registry import ModelRegistry
import lightgbm as lgb

# Current: 3 models
ensemble = RegimeAwareEnsemble()
assert len(ensemble.model_registry.get_models()) == 3

# Add new model (e.g., CatBoost for Phase 7)
ensemble.model_registry.register_model('catboost', CatBoostClassifier())
assert len(ensemble.model_registry.get_models()) == 4

# Remove underperforming model
ensemble.model_registry.remove_model('rf')
assert len(ensemble.model_registry.get_models()) == 3

# No code rewrite required - clean abstraction ✅
```

### 3. Regime-aware strategy switching works correctly ✅
```python
# Test regime → strategy pipeline
from trading.ml.ensemble.regime_aware_ensemble import RegimeAwareEnsemble
import numpy as np

ensemble = RegimeAwareEnsemble(n_estimators=10)
X = np.random.rand(100, 86)
y = np.random.randint(0, 2, 100)
ensemble.fit(X, y)

# Low volatility → stacking
regime_info = {'current_regime': 0, 'is_low_volatility': 1, 'regime_prob_0': 0.85, 'regime_prob_1': 0.15}
pred, meta = ensemble.predict_with_regime(X[0:1], regime_info)
assert meta['strategy'] == 'stacking'

# High volatility → voting
regime_info = {'current_regime': 1, 'is_low_volatility': 0, 'regime_prob_0': 0.20, 'regime_prob_1': 0.80}
pred, meta = ensemble.predict_with_regime(X[0:1], regime_info)
assert meta['strategy'] == 'voting'

# Transitional → dynamic
regime_info = {'current_regime': 0, 'is_low_volatility': 0, 'regime_prob_0': 0.55, 'regime_prob_1': 0.45}
pred, meta = ensemble.predict_with_regime(X[0:1], regime_info)
assert meta['strategy'] == 'dynamic'

# Pipeline bug-free ✅
```

---

## Notes

**Design decisions:**
- Use sklearn's VotingClassifier and StackingClassifier (battle-tested, don't hand-roll)
- **SECURITY CRITICAL:** Native JSON/text formats for XGBoost/LightGBM (no unsafe alternatives)
- joblib for Random Forest only (sklearn standard practice, acceptable)
- Simple feature importance aggregation (average across models, not complex WISFC initially)
- Reasonable hyperparameter defaults (focus on architecture, not squeezing every 0.1%)

**Deviations allowed (per GSD deviation rules):**
- Auto-fix bugs in regime-to-strategy mapping logic
- Add critical validation checks (regime probabilities sum to 1, etc.)
- Fix blocking errors in model loading/saving
- Ask about architectural changes (e.g., changing meta-model from LogisticRegression)
- Log non-critical enhancements (e.g., additional observability metrics)

**Out of scope (explicitly deferred):**
- Deep learning models (LSTM, Transformers) - Phase 7
- Real-time model retraining - deferred indefinitely
- Complex hyperparameter tuning (AutoML, GridSearch over all params)
- Online learning or incremental updates

**Security requirements (NON-NEGOTIABLE):**
- XGBoost models MUST use native JSON format
- LightGBM models MUST use native text format
- No unsafe serialization methods anywhere in codebase
- Verification in Task 3 to confirm safe formats

---

*Plan: 06-01-ensemble-model-framework*
*Phase: 6 of 8*
*Created: 2025-12-27*
